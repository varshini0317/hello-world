{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "s6Th_i1Sn09C"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b6b6c87ddb3b486fa60c37ba1b4d2b79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3714c463d126490a89028869bd3ba178",
              "IPY_MODEL_501ceb0eafff46018e62f8fbe1b64be9",
              "IPY_MODEL_7efbb1509ab74e82a18f40e68d654684"
            ],
            "layout": "IPY_MODEL_bdd4dd42e05d43f3b931a467b587f290"
          }
        },
        "3714c463d126490a89028869bd3ba178": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03f75bb7629f4f2c925a857e706d1adf",
            "placeholder": "​",
            "style": "IPY_MODEL_2b8db1532b8c42bab62275b79921359c",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "501ceb0eafff46018e62f8fbe1b64be9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdf84429c4d346afbc0944ee06f8d19c",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3f90cfe350ea4d6ba6aaee840f3634cc",
            "value": 26
          }
        },
        "7efbb1509ab74e82a18f40e68d654684": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6fabdbac92f4af2a3f182d930b2adec",
            "placeholder": "​",
            "style": "IPY_MODEL_5a8443d67fae43638325216826b1ac00",
            "value": " 26.0/26.0 [00:00&lt;00:00, 2.76kB/s]"
          }
        },
        "bdd4dd42e05d43f3b931a467b587f290": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03f75bb7629f4f2c925a857e706d1adf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b8db1532b8c42bab62275b79921359c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bdf84429c4d346afbc0944ee06f8d19c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f90cfe350ea4d6ba6aaee840f3634cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c6fabdbac92f4af2a3f182d930b2adec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a8443d67fae43638325216826b1ac00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "411f4d2c5513454eaa260c4e541cfe6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ebc778c766494faabb9f8b88ee528df3",
              "IPY_MODEL_7ebf055800654b0c905ba2eb868a48a4",
              "IPY_MODEL_e840223e347c417a8c6b5b9ef0640201"
            ],
            "layout": "IPY_MODEL_41ae4848894345f489a8c66750970c73"
          }
        },
        "ebc778c766494faabb9f8b88ee528df3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d6b2a46ae6a4f558ffb248ae4d511cf",
            "placeholder": "​",
            "style": "IPY_MODEL_47b903dabd5a4f88932fd44f56e9e4d8",
            "value": "vocab.json: 100%"
          }
        },
        "7ebf055800654b0c905ba2eb868a48a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83233900cf38415f82a3940e5bcce073",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_526ce59d3a854e19b18c8a5141c1b199",
            "value": 1042301
          }
        },
        "e840223e347c417a8c6b5b9ef0640201": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_124c2565fa4048039e9a331e9f0740e3",
            "placeholder": "​",
            "style": "IPY_MODEL_6169f5e6bbe647d4883c24f96d7df55b",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 19.1MB/s]"
          }
        },
        "41ae4848894345f489a8c66750970c73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d6b2a46ae6a4f558ffb248ae4d511cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47b903dabd5a4f88932fd44f56e9e4d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83233900cf38415f82a3940e5bcce073": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "526ce59d3a854e19b18c8a5141c1b199": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "124c2565fa4048039e9a331e9f0740e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6169f5e6bbe647d4883c24f96d7df55b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5bcb9b7c3f8c476ea7cbfbef62f30074": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aabd2d672c9b4d2cba7bc1a0e55849a1",
              "IPY_MODEL_81af9b2221264a0a959b45d5e205a69f",
              "IPY_MODEL_4fa7d4d5f3624575bf7d77c9ef4104d8"
            ],
            "layout": "IPY_MODEL_99df569e635243d496a11ac85e3353fa"
          }
        },
        "aabd2d672c9b4d2cba7bc1a0e55849a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1598488429f447fa81af77a3c597eeb8",
            "placeholder": "​",
            "style": "IPY_MODEL_604f16ceb23a426c8c91d36e833c52fe",
            "value": "merges.txt: 100%"
          }
        },
        "81af9b2221264a0a959b45d5e205a69f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76410e576bad4b278430b23eafd97de3",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a2c2b86a268e402986514b8c330deb16",
            "value": 456318
          }
        },
        "4fa7d4d5f3624575bf7d77c9ef4104d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b084d4cf2fa4d7d935576c688baf8c0",
            "placeholder": "​",
            "style": "IPY_MODEL_bb6aac6f26d74aa3ac703c50e5fe9bb5",
            "value": " 456k/456k [00:00&lt;00:00, 5.15MB/s]"
          }
        },
        "99df569e635243d496a11ac85e3353fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1598488429f447fa81af77a3c597eeb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "604f16ceb23a426c8c91d36e833c52fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76410e576bad4b278430b23eafd97de3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2c2b86a268e402986514b8c330deb16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5b084d4cf2fa4d7d935576c688baf8c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb6aac6f26d74aa3ac703c50e5fe9bb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10101b6fa5ed44dea8d1ae27fdc57f45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d48b8251707940ed9b5368a960510abf",
              "IPY_MODEL_9966fa4a82fc47ca90574dbd79f1a7d9",
              "IPY_MODEL_4b10cb49442e443ab8705936bad6ad33"
            ],
            "layout": "IPY_MODEL_baea41d9bd804d918481a4b275573268"
          }
        },
        "d48b8251707940ed9b5368a960510abf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a082596f70a84fe3b633f6fa95ac3c2d",
            "placeholder": "​",
            "style": "IPY_MODEL_ec9542fa50d94aaa87707f5e8c2caa5f",
            "value": "tokenizer.json: 100%"
          }
        },
        "9966fa4a82fc47ca90574dbd79f1a7d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3061cc8ba354b5db007beffd1862211",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8293bc0440eb4fa0b3c3e618fbdf7886",
            "value": 1355256
          }
        },
        "4b10cb49442e443ab8705936bad6ad33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5b5f3ee6fc64debbef6a7beff88da16",
            "placeholder": "​",
            "style": "IPY_MODEL_f1ce7c787b9948eabd0e0dbef572aef1",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 28.2MB/s]"
          }
        },
        "baea41d9bd804d918481a4b275573268": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a082596f70a84fe3b633f6fa95ac3c2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec9542fa50d94aaa87707f5e8c2caa5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3061cc8ba354b5db007beffd1862211": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8293bc0440eb4fa0b3c3e618fbdf7886": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5b5f3ee6fc64debbef6a7beff88da16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1ce7c787b9948eabd0e0dbef572aef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ceead07728cd4f909146eb8ce3ab586a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_016d6f0b03b34397b05c65ce5e8ce950",
              "IPY_MODEL_e0e5ba5000a7494c9696c6dca6db9246",
              "IPY_MODEL_228967fb4c2044bd821bb16ef8fab147"
            ],
            "layout": "IPY_MODEL_f6586238189c4e55b764d437b83d13d8"
          }
        },
        "016d6f0b03b34397b05c65ce5e8ce950": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b98a2f1cc8b4e02a1654b55f15e30c0",
            "placeholder": "​",
            "style": "IPY_MODEL_0b4644bf7f144bf9a71b37e8119b81dc",
            "value": "config.json: 100%"
          }
        },
        "e0e5ba5000a7494c9696c6dca6db9246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b994b5b65cef4d98b09d35691793903e",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ddb6ebea89b0437b87b86f806e1cec5d",
            "value": 665
          }
        },
        "228967fb4c2044bd821bb16ef8fab147": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a7cd89c94f442f59d1f1e3bcc70e1cd",
            "placeholder": "​",
            "style": "IPY_MODEL_0d835c8e257b417c971f89ef9dc54ca4",
            "value": " 665/665 [00:00&lt;00:00, 59.7kB/s]"
          }
        },
        "f6586238189c4e55b764d437b83d13d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b98a2f1cc8b4e02a1654b55f15e30c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b4644bf7f144bf9a71b37e8119b81dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b994b5b65cef4d98b09d35691793903e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddb6ebea89b0437b87b86f806e1cec5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5a7cd89c94f442f59d1f1e3bcc70e1cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d835c8e257b417c971f89ef9dc54ca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f11f45f57492409b94e0240b07221657": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ad05aa380ea44d948f98e9e0957722f0",
              "IPY_MODEL_9249159280fb41d1bb3fbb9b88a15796",
              "IPY_MODEL_0eee7a1982b34d549addb86b6d31ec42"
            ],
            "layout": "IPY_MODEL_334c5c6bb15e407583e5f06e48ab8d74"
          }
        },
        "ad05aa380ea44d948f98e9e0957722f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b85268c3763247fca29bf6ab1407579b",
            "placeholder": "​",
            "style": "IPY_MODEL_ad6482b772a9491d88e9cadb0f9803bf",
            "value": "model.safetensors: 100%"
          }
        },
        "9249159280fb41d1bb3fbb9b88a15796": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9f31a426fa24c9cac42a20b0b681823",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1bf7beb15e1e4458af8de3ffc0be1e0c",
            "value": 548105171
          }
        },
        "0eee7a1982b34d549addb86b6d31ec42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c3a64def99141cd94b131a8e6eeeb53",
            "placeholder": "​",
            "style": "IPY_MODEL_6bb2a3357e414020af8f323598e329e9",
            "value": " 548M/548M [00:02&lt;00:00, 226MB/s]"
          }
        },
        "334c5c6bb15e407583e5f06e48ab8d74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b85268c3763247fca29bf6ab1407579b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad6482b772a9491d88e9cadb0f9803bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f9f31a426fa24c9cac42a20b0b681823": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bf7beb15e1e4458af8de3ffc0be1e0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c3a64def99141cd94b131a8e6eeeb53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bb2a3357e414020af8f323598e329e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1ad369c8f9ee4620b50b60d67e1dca2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8cb2a3ecee948d1aa72eab445e9e195",
              "IPY_MODEL_90211dd768c7417e87621e15a682909f",
              "IPY_MODEL_b6e2d9ea86f94fa8abe729ad3f97c91e"
            ],
            "layout": "IPY_MODEL_2df45a6e7f7b4c2bbc70d16cf494f21c"
          }
        },
        "c8cb2a3ecee948d1aa72eab445e9e195": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f901408bf9ff4339b04bdf97bfaf5b1e",
            "placeholder": "​",
            "style": "IPY_MODEL_00015664204c4fb5a9fc03debf891a5e",
            "value": "generation_config.json: 100%"
          }
        },
        "90211dd768c7417e87621e15a682909f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed77dd2f6e0d41b28efdf077bca1394c",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7be317c9e3545f48a8b892596b6bb2f",
            "value": 124
          }
        },
        "b6e2d9ea86f94fa8abe729ad3f97c91e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd6cbb64fc0d4121b64e7280ae72b373",
            "placeholder": "​",
            "style": "IPY_MODEL_f915f2496e1340b7bbd0921f46c57937",
            "value": " 124/124 [00:00&lt;00:00, 10.3kB/s]"
          }
        },
        "2df45a6e7f7b4c2bbc70d16cf494f21c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f901408bf9ff4339b04bdf97bfaf5b1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00015664204c4fb5a9fc03debf891a5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed77dd2f6e0d41b28efdf077bca1394c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7be317c9e3545f48a8b892596b6bb2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd6cbb64fc0d4121b64e7280ae72b373": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f915f2496e1340b7bbd0921f46c57937": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This initial model is is only used at the starting phase of the project.It is not linked with the current project code.The current project code is started frrom the heading of Rule based model."
      ],
      "metadata": {
        "id": "_3xWUEBR4FpA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial model\n",
        "\n"
      ],
      "metadata": {
        "id": "s6Th_i1Sn09C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# import json\n",
        "# import csv\n",
        "# import json\n",
        "# import sqlite3\n",
        "\n",
        "\n",
        "# #Load JSON data\n",
        "# file_path = '/content/drive/MyDrive/THIRUKURAL/thirukural_git.json'\n",
        "# with open(file_path, 'r', encoding='utf-8') as file:\n",
        "#     data = json.load(file)['kurals']  # Adjust this depending on the structure of your JSON\n",
        "\n",
        "# #Prepare to write to CSV\n",
        "# csv_file_path = 'output.csv'\n",
        "# with open(csv_file_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "#     fieldnames = ['chapter', 'number', 'section', 'kural', 'meaning_ta_mu_va', 'meaning_ta_salamon', 'meaning_en']\n",
        "#     writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "#     writer.writeheader()\n",
        "\n",
        "#     for item in data:\n",
        "#         #Prepare data, combining kural parts\n",
        "#         kural_combined = ' '.join(item['kural'])\n",
        "\n",
        "#         row = {\n",
        "#             'chapter': item['chapter'],\n",
        "#             'number': item['number'],\n",
        "#             'section': item['section'],\n",
        "#             'kural': kural_combined,\n",
        "#             'meaning_ta_mu_va': item['meaning'].get('ta_mu_va', ''),\n",
        "#             'meaning_ta_salamon': item['meaning'].get('ta_salamon', ''),\n",
        "#             'meaning_en': item['meaning'].get('en', '')\n",
        "#         }\n",
        "#         writer.writerow(row)\n",
        "\n",
        "# print(f\"Data has been written to {csv_file_path}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "L0hyLUm_a7UI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Connect to SQLite database (or create it if it doesn't exist)\n",
        "# conn = sqlite3.connect('kurals.db')\n",
        "# c = conn.cursor()\n",
        "\n",
        "# # Define the table schema\n",
        "# c.execute('''\n",
        "# CREATE TABLE IF NOT EXISTS kural (\n",
        "#     id INTEGER PRIMARY KEY,\n",
        "#     chapter TEXT,\n",
        "#     number INTEGER,\n",
        "#     section TEXT,\n",
        "#     kural TEXT,\n",
        "#     meaning_ta_mu_va TEXT,\n",
        "#     meaning_ta_salamon TEXT,\n",
        "#     meaning_en TEXT\n",
        "# )\n",
        "# ''')\n",
        "\n",
        "# # Insert data into the table\n",
        "# for item in data:\n",
        "#     kural_combined = ' '.join(item['kural'])  # Combine the kural parts into a single string\n",
        "\n",
        "#     c.execute('''\n",
        "#     INSERT INTO kural (chapter, number, section, kural, meaning_ta_mu_va, meaning_ta_salamon, meaning_en) VALUES (?, ?, ?, ?, ?, ?, ?)\n",
        "#     ''', (\n",
        "#         item['chapter'],\n",
        "#         item['number'],\n",
        "#         item['section'],\n",
        "#         kural_combined,\n",
        "#         item['meaning'].get('ta_mu_va', ''),\n",
        "#         item['meaning'].get('ta_salamon', ''),\n",
        "#         item['meaning'].get('en', '')\n",
        "#     ))\n",
        "\n",
        "# # Commit changes and close the connection\n",
        "# conn.commit()\n",
        "# conn.close()\n"
      ],
      "metadata": {
        "id": "6mg5O4VUSDNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RULE BASED\n"
      ],
      "metadata": {
        "id": "Q9kIlZv6T3lm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxYies4_Wa3D",
        "outputId": "eecaad94-44cd-4065-da10-7d88a00632cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount Google drive to read data from it\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install openai==0.28\n",
        "!pip install googletrans==4.0.0-rc1\n",
        "!pip install googletrans==4.0.0-rc1 openai\n",
        "!pip install transformers torch\n",
        "!pip install transformers[torch] -U\n",
        "\n",
        "!pip install --upgrade pip\n",
        "!pip install --upgrade transformers\n",
        "!pip install --upgrade torch\n",
        "!pip install --upgrade accelerate\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4g4sAANlRxz",
        "outputId": "33364085-126d-44e9-adf8-130931b55720"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.61.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (3.11.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2025.1.31)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.18.3)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.61.1\n",
            "    Uninstalling openai-1.61.1:\n",
            "      Successfully uninstalled openai-1.61.1\n",
            "Successfully installed openai-0.28.0\n",
            "Collecting googletrans==4.0.0-rc1\n",
            "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting httpx==0.13.3 (from googletrans==4.0.0-rc1)\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2025.1.31)\n",
            "Collecting hstspreload (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hstspreload-2025.1.1-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\n",
            "Collecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl.metadata (32 kB)\n",
            "Collecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl.metadata (7.0 kB)\n",
            "Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Downloading hstspreload-2025.1.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17397 sha256=15447ebc87ff6fc501197c4e468ddab56f727c90a170b470ff08c19edb3bb0e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/17/6f/66a045ea3d168826074691b4b787b8f324d3f646d755443fda\n",
            "Successfully built googletrans\n",
            "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
            "  Attempting uninstall: hyperframe\n",
            "    Found existing installation: hyperframe 6.1.0\n",
            "    Uninstalling hyperframe-6.1.0:\n",
            "      Successfully uninstalled hyperframe-6.1.0\n",
            "  Attempting uninstall: hpack\n",
            "    Found existing installation: hpack 4.1.0\n",
            "    Uninstalling hpack-4.1.0:\n",
            "      Successfully uninstalled hpack-4.1.0\n",
            "  Attempting uninstall: h11\n",
            "    Found existing installation: h11 0.14.0\n",
            "    Uninstalling h11-0.14.0:\n",
            "      Successfully uninstalled h11-0.14.0\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: h2\n",
            "    Found existing installation: h2 4.2.0\n",
            "    Uninstalling h2-4.2.0:\n",
            "      Successfully uninstalled h2-4.2.0\n",
            "  Attempting uninstall: httpcore\n",
            "    Found existing installation: httpcore 1.0.7\n",
            "    Uninstalling httpcore-1.0.7:\n",
            "      Successfully uninstalled httpcore-1.0.7\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.1\n",
            "    Uninstalling httpx-0.28.1:\n",
            "      Successfully uninstalled httpx-0.28.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langsmith 0.3.11 requires httpx<1,>=0.23.0, but you have httpx 0.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2025.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n",
            "Requirement already satisfied: googletrans==4.0.0-rc1 in /usr/local/lib/python3.11/dist-packages (4.0.0rc1)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (0.28.0)\n",
            "Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.11/dist-packages (from googletrans==4.0.0-rc1) (0.13.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2025.1.31)\n",
            "Requirement already satisfied: hstspreload in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2025.1.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\n",
            "Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2.10)\n",
            "Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.5.0)\n",
            "Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.11/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.1)\n",
            "Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.11/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (0.9.0)\n",
            "Requirement already satisfied: h2==3.* in /usr/local/lib/python3.11/dist-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.2.0)\n",
            "Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.11/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (5.2.0)\n",
            "Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.11/dist-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1) (3.0.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai) (3.11.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai) (2.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (1.18.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m843.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n",
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.11/dist-packages (4.48.3)\n",
            "Collecting transformers[torch]\n",
            "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (4.67.1)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (2.5.1+cu124)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers[torch]) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers[torch]) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->transformers[torch]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0->transformers[torch]) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers[torch]) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0->transformers[torch]) (3.0.2)\n",
            "Downloading transformers-4.49.0-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.48.3\n",
            "    Uninstalling transformers-4.48.3:\n",
            "      Successfully uninstalled transformers-4.48.3\n",
            "Successfully installed transformers-4.49.0\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
            "Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.0.1\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.49.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Collecting torch\n",
            "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting triton==3.2.0 (from torch)\n",
            "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m65.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-cusparselt-cu12, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu124\n",
            "    Uninstalling torch-2.5.1+cu124:\n",
            "      Successfully uninstalled torch-2.5.1+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\n",
            "torchvision 0.20.1+cu124 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\n",
            "fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cusparselt-cu12-0.6.2 torch-2.6.0 triton-3.2.0\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-1.4.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.28.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.10.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.1.31)\n",
            "Downloading accelerate-1.4.0-py3-none-any.whl (342 kB)\n",
            "Installing collected packages: accelerate\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.3.0\n",
            "    Uninstalling accelerate-1.3.0:\n",
            "      Successfully uninstalled accelerate-1.3.0\n",
            "Successfully installed accelerate-1.4.0\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip install --upgrade torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W7FViv8OaCHa",
        "outputId": "9a73c16b-5a54-4e03-aa8b-0501069655e0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0)\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp311-cp311-linux_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Collecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.21.0%2Bcu118-cp311-cp311-linux_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Collecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.6.0%2Bcu118-cp311-cp311-linux_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==9.1.0.70 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.21.5 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl (147.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading https://download.pytorch.org/whl/cu118/torch-2.6.0%2Bcu118-cp311-cp311-linux_x86_64.whl (848.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m848.7/848.7 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu118/torchvision-0.21.0%2Bcu118-cp311-cp311-linux_x86_64.whl (6.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading https://download.pytorch.org/whl/cu118/torchaudio-2.6.0%2Bcu118-cp311-cp311-linux_x86_64.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0\n",
            "    Uninstalling torch-2.6.0:\n",
            "      Successfully uninstalled torch-2.6.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu124\n",
            "    Uninstalling torchvision-0.20.1+cu124:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu124\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.5.1+cu124\n",
            "    Uninstalling torchaudio-2.5.1+cu124:\n",
            "      Successfully uninstalled torchaudio-2.5.1+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0+cu118 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.21.5 nvidia-nvtx-cu11-11.8.86 torch-2.6.0+cu118 torchaudio-2.6.0+cu118 torchvision-0.21.0+cu118\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen"
                ]
              },
              "id": "c044a75b05f34fa5848813944d9d70cf"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import re\n",
        "import googletrans\n",
        "from googletrans import Translator\n",
        "import json\n",
        "import openai\n",
        "\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import accelerate\n",
        "print(accelerate.__version__)  # This will print the version of the accelerate library\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from transformers import GPT2Tokenizer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import pandas as pd\n",
        "from io import BytesIO\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nVodh40AjQ-m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce46dae3-a8b5-4254-cf49-0dd2b1694e94"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_thirukkural_data(file_path):\n",
        "    \"\"\"Load Thirukkural data from a JSON file.\"\"\"\n",
        "    with open(file_path, 'r') as file:\n",
        "        return json.load(file)\n",
        "\n",
        "kural_data = load_thirukkural_data(\"/content/thirukural_git (1).json\")"
      ],
      "metadata": {
        "id": "HazC8pljE8AN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the function to get responses based on Thirukkural\n",
        "\n",
        "\n",
        "def get_thirukkural_response(kural_data, query_type, query_value, translate_to=None, author_alias=None, detail=None):\n",
        "    \"\"\"Retrieve a Thirukkural response based on query type, value, and optional author explanation.\"\"\"\n",
        "    translator = googletrans.Translator()\n",
        "    responses = []\n",
        "    author_map = {\n",
        "        'mu_va': 'ta_mu_va',\n",
        "        'mu va': 'ta_mu_va',\n",
        "        'ta_mu_va': 'ta_mu_va',\n",
        "        'salamon': 'ta_salamon',\n",
        "        'ta_salamon': 'ta_salamon',\n",
        "        'சாலமன் பாப்பையா': 'ta_salamon'\n",
        "    }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def translate(text, target_lang):\n",
        "        \"\"\"Helper function to translate text using Google Translate.\"\"\"\n",
        "        if target_lang == 'en':\n",
        "            return translator.translate(text, src='ta', dest='en').text\n",
        "        elif target_lang == 'ta':\n",
        "            return translator.translate(text, src='en', dest='ta').text\n",
        "        return text\n",
        "\n",
        "    # Process queries based on type\n",
        "    kurals_to_process = []\n",
        "    if query_type == 'kural_number':\n",
        "        kural = next((k for k in kural_data['kurals'] if k['number'] == int(query_value)), None)\n",
        "        if kural:\n",
        "            kurals_to_process.append(kural)\n",
        "    elif query_type in ['keyword', 'chapter_name', 'section_name']:\n",
        "        if query_type == 'keyword':\n",
        "            kurals_to_process = [k for k in kural_data['kurals'] if query_value.lower() in \" \".join(k['kural']).lower()]\n",
        "        elif query_type == 'chapter_name':\n",
        "            kurals_to_process = [k for k in kural_data['kurals'] if k['chapter'].lower() == query_value.lower()]\n",
        "        elif query_type == 'section_name':\n",
        "            kurals_to_process = [k for k in kural_data['kurals'] if k['section'].lower() == query_value.lower()]\n",
        "\n",
        "    # Generate responses for each kural\n",
        "    for kural in kurals_to_process:\n",
        "        kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "        if translate_to == 'ta':\n",
        "            english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "            translated_text = translate(english_meaning, 'ta')\n",
        "            responses.append(f\"{kural_text}\\nMeaning (Tamil): {translated_text}\")\n",
        "        elif author_alias and author_alias in ['mu_va', 'salamon']:\n",
        "            author_key = 'ta_' + author_alias if 'ta_' not in author_alias else author_alias\n",
        "            explanation = kural['meaning'].get(author_key, \"No explanation available.\")\n",
        "            translated_text = translate(explanation, 'en')\n",
        "            responses.append(f\"{kural_text}\\nExplanation by {author_alias} (English): {translated_text}\")\n",
        "        else:\n",
        "            english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "            responses.append(f\"{kural_text}\\nMeaning (English): {english_meaning}\")\n",
        "\n",
        "    return \"\\n\".join(responses) if responses else \"No Kural found matching the query.\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # # Helper function to perform translation\n",
        "    # def translate(text, target_lang):\n",
        "    #     \"\"\"Translate text using Google Translate.\"\"\"\n",
        "    #     if target_lang:\n",
        "    #         try:\n",
        "    #             return translator.translate(text, src='ta' if target_lang == 'en' else 'en', dest=target_lang).text\n",
        "    #         except Exception as e:\n",
        "    #             print(f\"Translation failed: {e}\")\n",
        "    #             return text\n",
        "    #     return text\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Identify kurals based on query_type\n",
        "    kurals_to_process = []\n",
        "    if query_type == 'section_name':\n",
        "        kurals_to_process = [k for k in kural_data['kurals'] if k['section'] == query_value]\n",
        "    elif query_type == 'chapter_name':\n",
        "        kurals_to_process = [k for k in kural_data['kurals'] if k['chapter'] == query_value]\n",
        "    elif query_type in ['keyword', 'starts_with', 'ends_with']:\n",
        "        for kural in kural_data['kurals']:\n",
        "            if (query_type == 'keyword' and query_value in ' '.join(kural['kural']).lower()) or \\\n",
        "               (query_type == 'starts_with' and kural['kural'][0].startswith(query_value)) or \\\n",
        "               (query_type == 'ends_with' and kural['kural'][-1].endswith(query_value)):\n",
        "                kurals_to_process.append(kural)\n",
        "\n",
        "    # Generate responses for each kural\n",
        "    for kural in kurals_to_process:\n",
        "        kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "        if translate_to == 'ta':\n",
        "            english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "            translated_text = translate(english_meaning, 'en', 'ta')\n",
        "            responses.append(f\"{kural_text}\\nMeaning (Tamil): {translated_text}\")\n",
        "        elif author_alias and author_alias in author_map:\n",
        "            author_key = author_map[author_alias]\n",
        "            explanation = kural['meaning'].get(author_key, \"No explanation available.\")\n",
        "            if translate_to == 'en':\n",
        "                translated_text = translate(explanation, 'ta', 'en')\n",
        "                responses.append(f\"{kural_text}\\nExplanation by {author_alias} (English): {translated_text}\")\n",
        "            else:\n",
        "                responses.append(f\"{kural_text}\\nExplanation by {author_alias}: {explanation}\")\n",
        "        else:\n",
        "            english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "            responses.append(f\"{kural_text}\\nMeaning (English): {english_meaning}\")\n",
        "\n",
        "\n",
        "\n",
        "    # Define a function to format the response for kurals\n",
        "    def format_kural_response(kural):\n",
        "        \"\"\"Format the response for a single kural with optional translation or explanation.\"\"\"\n",
        "        kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "        if author_alias and author_alias in author_map:\n",
        "            author_key = author_map[author_alias]\n",
        "            explanation = kural['meaning'].get(author_key, \"No explanation available.\")\n",
        "            if translate_to:\n",
        "                explanation = translate(explanation, translate_to)\n",
        "            response = f\"{kural_text}\\nExplanation by {author_key.replace('ta_', '')}: {explanation}\"\n",
        "        elif translate_to:\n",
        "            english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "            translated_meaning = translate(english_meaning, translate_to)\n",
        "            response = f\"{kural_text}\\nMeaning ({translate_to.capitalize()}): {translated_meaning}\"\n",
        "        else:\n",
        "            english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "            response = f\"{kural_text}\\nMeaning (English): {english_meaning}\"\n",
        "        return response\n",
        "\n",
        "\n",
        "        # Rule 1 & 2: Section and/or Chapter based queries\n",
        "    if query_type in ['section_name', 'chapter_name']:\n",
        "        for kural in kural_data['kurals']:\n",
        "            if (query_type == 'section_name' and kural['section'] == query_value) or \\\n",
        "               (query_type == 'chapter_name' and kural['chapter'] == query_value):\n",
        "                kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "                if author_alias and author_alias in author_map:\n",
        "                    author_key = author_map[author_alias]\n",
        "                    explanation = kural['meaning'].get(author_key, \"No explanation available.\")\n",
        "                    kural_text += f\"\\nExplanation by {author_key}: {explanation}\"\n",
        "                else:\n",
        "                    kural_text += f\"\\nMeaning (English): {kural['meaning']['en']}\"\n",
        "                responses.append(kural_text)\n",
        "\n",
        "    # Rule 3, 9: Keyword based English meanings\n",
        "    if query_type == 'keyword':\n",
        "        kurals_by_keyword = [kural for kural in kural_data['kurals'] if query_value in ' '.join(kural['kural']).lower()]\n",
        "        if detail == 'english_meaning':\n",
        "            responses.extend([f\"Kural {k['number']}: {' '.join(k['kural'])}\\nMeaning (English): {k['meaning']['en']}\" for k in kurals_by_keyword])\n",
        "        elif detail == 'chapter_list':\n",
        "            chapters = set(k['chapter'] for k in kurals_by_keyword)\n",
        "            responses.extend(list(chapters))\n",
        "        else:\n",
        "            for kural in kurals_by_keyword:\n",
        "                if author_alias in author_map:\n",
        "                    kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "                    author_key = author_map[author_alias]\n",
        "                    explanation = kural['meaning'].get(author_key, \"No explanation available.\")\n",
        "                    responses.append(f\"{kural_text}\\nExplanation by {author_key}: {explanation}\")\n",
        "\n",
        "    # Rule 7, 8, 13, 14: Kurals starting/ending with a specific word\n",
        "    if query_type == 'starts_with':\n",
        "        responses.extend([f\"Kural {k['number']}: {' '.join(k['kural'])}\" for k in kural_data['kurals'] if k['kural'][0].startswith(query_value)])\n",
        "    if query_type == 'ends_with':\n",
        "        responses.extend([f\"Kural {k['number']}: {' '.join(k['kural'])}\" for k in kural_data['kurals'] if k['kural'][-1].endswith(query_value)])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Fetch by kural number\n",
        "    if query_type == 'kural_number':\n",
        "        kural_match = next((k for k in kural_data['kurals'] if k['number'] == int(query_value)), None)\n",
        "        if kural_match:\n",
        "            kural_text = f\"Kural {kural_match['number']}: {' '.join(kural_match['kural'])}\"\n",
        "            if author_alias and author_alias in author_map:\n",
        "                author_key = author_map[author_alias]\n",
        "                author_explanation = kural_match['meaning'].get(author_key, \"No explanation available for this author.\")\n",
        "                responses.append(f\"{kural_text}\\nExplanation by {author_key.replace('ta_', '')}: {author_explanation}\")\n",
        "            else:\n",
        "                english_meaning = kural_match['meaning'].get('en', \"No English translation available.\")\n",
        "                responses.append(f\"{kural_text}\\nMeaning (English): {english_meaning}\")\n",
        "\n",
        "    # Fetch by chapter name\n",
        "    elif query_type == 'chapter_name':\n",
        "        kurals_in_chapter = [k for k in kural_data['kurals'] if k['chapter'].lower() == query_value.lower()]\n",
        "        for kural in kurals_in_chapter:\n",
        "            kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "            if author_alias and author_alias in author_map:\n",
        "                author_key = author_map[author_alias]\n",
        "                explanation = kural['meaning'].get(author_key, \"No explanation available.\")\n",
        "                responses.append(f\"{kural_text}\\nExplanation by {author_key.replace('ta_', '')}: {explanation}\")\n",
        "            else:\n",
        "                english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "                responses.append(f\"{kural_text}\\nMeaning (English): {english_meaning}\")\n",
        "\n",
        "    # Fetch by section name\n",
        "    elif query_type == 'section_name':\n",
        "        chapters_in_section = set(k['chapter'] for k in kural_data['kurals'] if k['section'].lower() == query_value.lower())\n",
        "        for chapter in chapters_in_section:\n",
        "            kurals_in_chapter = [k for k in kural_data['kurals'] if k['chapter'].lower() == chapter.lower()]\n",
        "            chapter_responses = []\n",
        "            for kural in kurals_in_chapter:\n",
        "                kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "                english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "                chapter_responses.append(f\"{kural_text}\\nMeaning (English): {english_meaning}\")\n",
        "            responses.append(f\"Chapter: {chapter}\\n\" + \"\\n\".join(chapter_responses))\n",
        "\n",
        "\n",
        "                # Fetch by keyword in kural, which checks for keywords in the text of the kural\n",
        "    elif query_type == 'keyword':\n",
        "        kurals_by_keyword = [kural for kural in kural_data['kurals'] if query_value in \" \".join(kural['kural']).lower()]\n",
        "        for kural in kurals_by_keyword:\n",
        "            kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "            if author_alias and author_alias in author_map:\n",
        "                author_key = author_map[author_alias]\n",
        "                explanation = kural['meaning'].get(author_key, \"No explanation available.\")\n",
        "                responses.append(f\"{kural_text}\\nExplanation by {author_key.replace('ta_', '')}: {explanation}\")\n",
        "            else:\n",
        "                english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "                responses.append(f\"{kural_text}\\nMeaning (English): {english_meaning}\")\n",
        "\n",
        "\n",
        "# Logic to handle different types of queries\n",
        "    elif query_type == 'keyword':\n",
        "        if detail == 'starts_with':\n",
        "            kurals_filtered = [kural for kural in kural_data['kurals'] if kural['kural'][0].startswith(query_value)]\n",
        "        elif detail == 'ends_with':\n",
        "            kurals_filtered = [kural for kural in kural_data['kurals'] if kural['kural'][-1].endswith(query_value)]\n",
        "        for kural in kurals_filtered:\n",
        "            kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "            responses.append(kural_text)\n",
        "\n",
        "    elif query_type == 'author_translation':\n",
        "        kurals_filtered = [kural for kural in kural_data['kurals'] if author_alias in kural['meaning']]\n",
        "        for kural in kurals_filtered:\n",
        "            explanation = kural['meaning'][author_alias]\n",
        "            kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\\nExplanation by {author_alias}: {explanation}\"\n",
        "            responses.append(kural_text)\n",
        "\n",
        "    elif query_type == 'chapter_count':\n",
        "        count = sum(1 for kural in kural_data['kurals'] if kural['chapter'] == query_value)\n",
        "        responses.append(f\"Total kurals in chapter '{query_value}': {count}\")\n",
        "\n",
        "    # Check for the correct handling of the 'author_translation' query type\n",
        "    elif query_type == 'author_translation':\n",
        "        # Assuming query_value should be something like 'ta_mu_va'\n",
        "        kurals_filtered = [kural for kural in kural_data['kurals'] if query_value in kural['meaning']]\n",
        "        for kural in kurals_filtered:\n",
        "            explanation = kural['meaning'].get(query_value)\n",
        "            if explanation:  # Ensure there's a translation available\n",
        "                kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\\nExplanation by {query_value}: {explanation}\"\n",
        "                responses.append(kural_text)\n",
        "\n",
        "\n",
        "\n",
        "    # Fetch kurals that start or end with a specific word\n",
        "    elif query_type == 'starts_with' or query_type == 'ends_with':\n",
        "        kurals_filtered = [\n",
        "            kural for kural in kural_data['kurals']\n",
        "            if (query_type == 'starts_with' and kural['kural'][0].startswith(query_value)) or\n",
        "               (query_type == 'ends_with' and kural['kural'][1].endswith(query_value))\n",
        "        ]\n",
        "        for kural in kurals_filtered:\n",
        "            kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "            english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "            responses.append(f\"{kural_text}\\nMeaning (English): {english_meaning}\")\n",
        "\n",
        "            # Fetch kurals containing a keyword with different requirements\n",
        "    elif query_type == 'keyword':\n",
        "        filtered_kurals = [kural for kural in kural_data['kurals'] if query_value in \" \".join(kural['kural']).lower()]\n",
        "        if detail == 'chapter_list':\n",
        "            # List chapters that contain the keyword\n",
        "            chapter_set = set(kural['chapter'] for kural in filtered_kurals)\n",
        "            responses = list(chapter_set)\n",
        "        elif detail in ['mu_va', 'ta_salamon']:\n",
        "            # Show kural and explanation by the specific author for the keyword\n",
        "            for kural in filtered_kurals:\n",
        "                kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "                author_explanation = kural['meaning'].get(detail, \"No explanation available.\")\n",
        "                responses.append(f\"{kural_text}\\nExplanation by {detail}: {author_explanation}\")\n",
        "        elif detail == 'starts_with':\n",
        "            # Kurals that start with the specific word\n",
        "            responses = [f\"Kural {k['number']}: {' '.join(k['kural'])}\" for k in filtered_kurals if k['kural'][0].startswith(query_value)]\n",
        "        elif detail == 'ends_with':\n",
        "            # Kurals that end with the specific word\n",
        "            responses = [f\"Kural {k['number']}: {' '.join(k['kural'])}\" for k in filtered_kurals if k['kural'][1].endswith(query_value)]\n",
        "        else:\n",
        "            # Default to showing English translation only\n",
        "            for kural in filtered_kurals:\n",
        "                kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "                english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "                responses.append(f\"{kural_text}\\nMeaning (English): {english_meaning}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return \"\\n\".join(responses) if responses else \"No Kural found matching the query.\"\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YwW0WiOoEsHf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Questions for test"
      ],
      "metadata": {
        "id": "rm2MT55PxCWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Translate English meanings to Tamil for kural number 1\n",
        "# print(get_thirukkural_response(kural_data, 'kural_number', '1', translate_to='ta'))\n",
        "\n",
        "# # Translate MuVa's explanation for kural number 1 into English\n",
        "# print(get_thirukkural_response(kural_data, 'kural_number', '1', translate_to='en', author_alias='mu_va'))\n",
        "\n",
        "# # Show direct English translation for kural number 1\n",
        "# print(get_thirukkural_response(kural_data, 'chapter', '1'))\n",
        "# # # Example usage of the function\n",
        "# query_type = 'kural_number'\n",
        "# query_value = 90  # Kural number to fetch\n",
        "# response = get_thirukkural_response(kural_data, query_type, query_value)\n",
        "# print(response)\n",
        "\n",
        "# # # # Test fetching a kural by number with explanations from specific authors\n",
        "# print(get_thirukkural_response(kural_data, 'kural_number', '7', author_alias='mu_va'))  # Mu Va's explanation\n",
        "# print(get_thirukkural_response(kural_data, 'kural_number', '10', author_alias='salamon'))  # Salamon's explanation\n",
        "# # # # Test fetching a kural by number with no specific author explanation\n",
        "# print(get_thirukkural_response(kural_data, 'kural_number', '1'))\n",
        "\n",
        "\n",
        "# # # # Query all chapters within a section, showing only English translations\n",
        "# print(get_thirukkural_response(kural_data, 'section_name', 'அறத்துப்பால்'))\n",
        "# # # # Fetching all kurals in a specific chapter and showing explanations from 'Mu Va'\n",
        "# print(get_thirukkural_response(kural_data, 'chapter_name', 'கடவுள் வாழ்த்து', author_alias='mu_va'))\n",
        "# # # Fetch chapters containing the word 'கேடு'\n",
        "#print(get_thirukkural_response(kural_data, 'keyword', 'கேடு', detail='chapter_list'))\n",
        "# print(get_thirukkural_response(kural_data, 'kural_number', '1', 'author_translation', 'ta_mu_va'))  # All kurals with 'ta_mu_va' translation\n",
        "# # # Fetch kurals with explanation by 'mu_va' for the keyword 'கேடு'\n",
        "# # print(get_thirukkural_response(kural_data, 'keyword', 'கேடு', author_alias='mu_va'))\n",
        "\n",
        "# # # Fetch kurals starting with 'அகர'\n",
        "# # print(get_thirukkural_response(kural_data, 'keyword', 'அகர', detail='starts_with'))\n",
        "\n",
        "# # # # Fetch kurals ending with 'உலகு'\n",
        "# # print(get_thirukkural_response(kural_data, 'keyword', 'உலகு', detail='ends_with'))\n",
        "# print(get_thirukkural_response(kural_data, 'kural_number', 1, 'mu va'))\n",
        "# #print(get_thirukkural_response(kural_data, 'kural_number', 1, 'salamon'))\n",
        "# # print(get_thirukkural_response(kural_data, 'kural_number', 1))\n",
        "\n",
        "# # Assuming kural_data is structured with 'chapters' as strings and 'kurals' as detailed objects\n",
        "\n",
        "# # Query a specific chapter with a request for an explanation from 'Mu Va'\n",
        "# # print(get_thirukkural_response(kural_data, 'chapter_name', 'கடவுள் வாழ்த்து', 'mu va'))\n",
        "\n",
        "# # Query all chapters within a section, only showing English translations\n",
        "# # print(get_thirukkural_response(kural_data, 'section_name', 'அறத்துப்பால்'))\n",
        "# # print(get_thirukkural_response(kural_data, 'chapter_name', 'கடவுள் வாழ்த்து'))  # All kurals in the chapter \"கடவுள் வாழ்த்து\"\n",
        "# # print(get_thirukkural_response(kural_data, 'keyword', 'உலகு'))           # Search by keyword in kurals\n",
        "# # Fetch all kurals containing the word 'கேடு' with English translation\n",
        "# # print(get_thirukkural_response(kural_data, 'keyword', 'கேடு'))\n",
        "# # # Fetch chapters containing the word 'கேடு'\n",
        "# # print(get_thirukkural_response(kural_data, 'keyword', 'கேடு', 'chapter_list'))\n",
        "# # # Fetch kurals starting with 'அகர'\n",
        "# # print(get_thirukkural_response(kural_data, 'keyword', 'அகர', 'starts_with'))\n",
        "\n",
        "# # # Fetch kurals ending with 'உலகு'\n",
        "# # print(get_thirukkural_response(kural_data, 'keyword', 'உலகு', 'ends_with'))\n",
        "\n",
        "# # # Fetch kurals with explanation by 'mu_va' for the keyword 'கேடு'\n",
        "# # print(get_thirukkural_response(kural_data, 'keyword', 'கேடு', 'mu_va'))\n",
        "\n",
        "# # print(get_thirukkural_response(kural_data, 'chapter_count', 'கடவுள் வாழ்த்து'))  # Count kurals in chapter\n",
        "\n",
        "\n",
        "\n",
        "# # print(get_thirukkural_response(kural_data, 'section_name', 'அறத்துப்பால்'))\n",
        "# # print(get_thirukkural_response(kural_data, 'chapter_name', 'கடவுள் வாழ்த்து', 'mu va'))\n",
        "# # print(get_thirukkural_response(kural_data, 'chapter_name', 'கடவுள் வாழ்த்து'))\n",
        "\n",
        "\n",
        "# # print(get_thirukkural_response(kural_data, 'section_name', 'அறத்துப்பால்', 'mu_va'))\n",
        "\n",
        "\n",
        "# # # Assuming kural_data is structured with 'chapters' as strings and 'kurals' as detailed objects\n",
        "\n",
        "# # print(get_thirukkural_response(kural_data, 'kural_number', 1, translate_to='en', author_alias='mu_va'))\n",
        "# # # Translate English meanings to Tamil for kural number 1\n",
        "# # print(get_thirukkural_response(kural_data, 'kural_number', '1', translate_to='ta'))\n",
        "\n",
        "# # # Translate MuVa's explanation for kural number 1 into English\n",
        "# print(get_thirukkural_response(kural_data, 'kural_number', '1', translate_to='en', author_alias='mu_va'))\n",
        "\n",
        "# # # Show direct English translation for kural number 1\n",
        "# # print(get_thirukkural_response(kural_data, 'chapter', '1'))\n",
        "\n",
        "\n",
        "\n",
        "# # # # Count of kurals in a specific chapter\n",
        "# # print(get_thirukkural_response(kural_data, 'chapter_count', 'கடவுள் வாழ்த்து'))\n",
        "\n",
        "# # # # Assuming kural_data is structured with 'chapters' as strings and 'kurals' as detailed objects\n",
        "\n",
        "# print(get_thirukkural_response(kural_data, 'kural_number', 1, translate_to='en', author_alias='mu_va'))\n",
        "# # # # Translate English meanings to Tamil for kural number 1\n",
        "# print(get_thirukkural_response(kural_data, 'kural_number', '1', translate_to='ta'))"
      ],
      "metadata": {
        "id": "nr7VY43UHVll"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATA FOR GPT2"
      ],
      "metadata": {
        "id": "UrcCQQWHWTgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Updated and complete answers\n",
        "answers = [\n",
        "    \"The opening verse praises the Almighty, highlighting the primacy of rain sourced from the waters governed by the divine. It sets the thematic tone of the text, emphasizing moral and ethical living under divine guidance, foundational in Tamil literature.\",\n",
        "    \"This verse suggests that a leader should not just plan but foresee outcomes and act accordingly, emphasizing proactive leadership.\",\n",
        "    \"It describes rain as the linchpin of the natural world and human civilization, essential for agriculture and life, advocating for environmental stewardship.\",\n",
        "    \"It extols the virtues of truthfulness and moral integrity above all else, stressing core Tamil cultural values of ethical living and honesty.\",\n",
        "    \"Discusses moderation in life and using resources wisely, echoing today’s global calls for sustainability and environmental conservation.\",\n",
        "    \"Highlights the importance of choosing friends who are virtuous and wise, advising to choose friends who uplift morally and intellectually.\",\n",
        "    \"Advises rulers to be just and ethical to ensure their reign is respected and enduring, emphasizing good governance based on ethical conduct and justice.\",\n",
        "    \"Emphasizes the role of justice as foundational to societal structure and leadership, advocating for fairness and righteousness in governance and daily life.\",\n",
        "    \"Celebrates the virtues of being a gracious host, depicting hospitality as a moral obligation and a sign of good character.\",\n",
        "    \"Elevates patience as a virtue that underpins effective problem-solving and peace, crucial for personal and social harmony.\",\n",
        "    \"Stresses the importance of learning from the wise, advocating for humility and the continuous pursuit of knowledge.\",\n",
        "    \"Warns about the destructive nature of anger, depicting it as a potent force that can ruin relationships and personal peace.\",\n",
        "    \"Advocates for self-restraint and control over one's desires, portraying self-discipline as essential for ethical living and spiritual growth.\",\n",
        "    \"Highlights the importance of expressing gratitude, enriching one's life and strengthening community bonds.\",\n",
        "    \"Advocates for truth as a fundamental moral value, essential for trust and integrity in personal and public spheres.\",\n",
        "    \"Discusses the negative impacts of greed, leading to moral and sometimes material ruin.\",\n",
        "    \"Discusses the virtues of benevolence and altruism, encouraging actions that promote the welfare of others as a foundation for a virtuous life.\",\n",
        "    \"Explores the concept of karma, or actions and their results, emphasizing moral responsibility and the ethical consequences of one's actions.\",\n",
        "    \"Underlines the ethical responsibilities of leaders towards their subjects, portraying leadership as not just a position but a moral duty to act for the common good.\",\n",
        "    \"Offers advice on prudent financial management and the dangers of mismanagement, stressing the balance between earning, saving, and spending wisely.\",\n",
        "    \"Links the acquisition of wealth to virtuous living, teaching that true wealth comes from living virtuously and using resources ethically.\",\n",
        "    \"Advocates for perseverance in the face of adversity, key to overcoming challenges and achieving goals.\",\n",
        "    \"Offers guidance on resilience and mental strength, stressing the importance of inner fortitude in navigating life's challenges.\",\n",
        "    \"Discusses ethical dilemmas and the importance of moral decision-making, central to personal integrity and societal respect.\",\n",
        "    \"Provides insights on resolving conflicts through diplomacy and understanding, advocating for peaceful resolution and understanding in conflicts.\"\n",
        "]\n",
        "# Completing the DataFrame creation by providing all necessary components including questions, answers, and verse numbers.\n",
        "\n",
        "\n",
        "\n",
        "# List of verse numbers\n",
        "verse_numbers = [\n",
        "    1, 5, 15, 25, 37, 45, 60, 75, 85, 90, 101, 110, 125, 135, 145, 150, 165, 175, 180, 190, 200, 210, 220, 230, 240\n",
        "]\n",
        "\n",
        "# List of questions\n",
        "questions = [\n",
        "    \"What is the meaning of Thirukkural verse 1 and its significance in Tamil literature?\",\n",
        "    \"How does verse 5 of the Thirukkural address the concept of leadership?\",\n",
        "    \"In what context does Thirukkural verse 15 discuss the importance of rain?\",\n",
        "    \"What moral values are emphasized in verse 25 of the Thirukkural?\",\n",
        "    \"How does verse 37 relate to the contemporary idea of sustainable living?\",\n",
        "    \"What advice does Thiruvalluvar offer about friendship in verse 45?\",\n",
        "    \"Discuss the implications of verse 60 on the conduct of a ruler.\",\n",
        "    \"How does verse 75 of the Thirukkural address the theme of justice?\",\n",
        "    \"What are the virtues extolled in verse 85 concerning hospitality?\",\n",
        "    \"How is the virtue of patience depicted in verse 90 of the Thirukkural?\",\n",
        "    \"Interpret the meaning behind the advice given in verse 101.\",\n",
        "    \"Explain how verse 110 discusses the repercussions of anger.\",\n",
        "    \"What insights does verse 125 provide on the importance of self-discipline?\",\n",
        "    \"Discuss the role of gratitude as depicted in verse 135 of the Thirukkural.\",\n",
        "    \"How does verse 145 advocate for truthfulness?\",\n",
        "    \"What does verse 150 say about the consequences of greed?\",\n",
        "    \"Explain the philosophical underpinnings of verse 165 in the Thirukkural.\",\n",
        "    \"How does verse 175 enhance our understanding of karma?\",\n",
        "    \"What lesson on leadership can be drawn from verse 180?\",\n",
        "    \"Analyze the advice on wealth management given in verse 190 of the Thirukkural.\",\n",
        "    \"What does verse 200 teach us about the balance between wealth and virtue?\",\n",
        "    \"How does verse 210 address the theme of determination?\",\n",
        "    \"Interpret the guidance provided in verse 220 on dealing with adversity.\",\n",
        "    \"What ethical considerations are highlighted in verse 230?\",\n",
        "    \"How does verse 240 of the Thirukkural relate to modern concepts of conflict resolution?\"\n",
        "]\n",
        "\n",
        "# Labels corresponding to each question\n",
        "labels = [\n",
        "    \"Meaning and Significance\", \"Leadership\", \"Importance of Rain\", \"Moral Values\",\n",
        "    \"Sustainable Living\", \"Friendship\", \"Ruler Conduct\", \"Justice\", \"Hospitality\",\n",
        "    \"Patience\", \"Advice Interpretation\", \"Repercussions of Anger\", \"Self-discipline\",\n",
        "    \"Gratitude\", \"Truthfulness\", \"Greed Consequences\", \"Philosophical Underpinnings\",\n",
        "    \"Karma\", \"Leadership\", \"Wealth Management\", \"Wealth and Virtue\", \"Determination\",\n",
        "    \"Dealing with Adversity\", \"Ethical Considerations\", \"Conflict Resolution\"\n",
        "]\n",
        "\n",
        "# Assembling the DataFrame\n",
        "dataframe = pd.DataFrame({\n",
        "    \"Verse Number\": verse_numbers,\n",
        "    \"Question\": questions,\n",
        "    \"Label\": labels,\n",
        "    \"Answer\": answers\n",
        "})\n",
        "\n",
        "dataframe"
      ],
      "metadata": {
        "id": "O7Gvp1PImjaY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        },
        "outputId": "47be9581-36b7-488c-ab47-52cee3320685"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Verse Number                                           Question  \\\n",
              "0              1  What is the meaning of Thirukkural verse 1 and...   \n",
              "1              5  How does verse 5 of the Thirukkural address th...   \n",
              "2             15  In what context does Thirukkural verse 15 disc...   \n",
              "3             25  What moral values are emphasized in verse 25 o...   \n",
              "4             37  How does verse 37 relate to the contemporary i...   \n",
              "5             45  What advice does Thiruvalluvar offer about fri...   \n",
              "6             60  Discuss the implications of verse 60 on the co...   \n",
              "7             75  How does verse 75 of the Thirukkural address t...   \n",
              "8             85  What are the virtues extolled in verse 85 conc...   \n",
              "9             90  How is the virtue of patience depicted in vers...   \n",
              "10           101  Interpret the meaning behind the advice given ...   \n",
              "11           110  Explain how verse 110 discusses the repercussi...   \n",
              "12           125  What insights does verse 125 provide on the im...   \n",
              "13           135  Discuss the role of gratitude as depicted in v...   \n",
              "14           145      How does verse 145 advocate for truthfulness?   \n",
              "15           150  What does verse 150 say about the consequences...   \n",
              "16           165  Explain the philosophical underpinnings of ver...   \n",
              "17           175  How does verse 175 enhance our understanding o...   \n",
              "18           180  What lesson on leadership can be drawn from ve...   \n",
              "19           190  Analyze the advice on wealth management given ...   \n",
              "20           200  What does verse 200 teach us about the balance...   \n",
              "21           210  How does verse 210 address the theme of determ...   \n",
              "22           220  Interpret the guidance provided in verse 220 o...   \n",
              "23           230  What ethical considerations are highlighted in...   \n",
              "24           240  How does verse 240 of the Thirukkural relate t...   \n",
              "\n",
              "                          Label  \\\n",
              "0      Meaning and Significance   \n",
              "1                    Leadership   \n",
              "2            Importance of Rain   \n",
              "3                  Moral Values   \n",
              "4            Sustainable Living   \n",
              "5                    Friendship   \n",
              "6                 Ruler Conduct   \n",
              "7                       Justice   \n",
              "8                   Hospitality   \n",
              "9                      Patience   \n",
              "10        Advice Interpretation   \n",
              "11       Repercussions of Anger   \n",
              "12              Self-discipline   \n",
              "13                    Gratitude   \n",
              "14                 Truthfulness   \n",
              "15           Greed Consequences   \n",
              "16  Philosophical Underpinnings   \n",
              "17                        Karma   \n",
              "18                   Leadership   \n",
              "19            Wealth Management   \n",
              "20            Wealth and Virtue   \n",
              "21                Determination   \n",
              "22       Dealing with Adversity   \n",
              "23       Ethical Considerations   \n",
              "24          Conflict Resolution   \n",
              "\n",
              "                                               Answer  \n",
              "0   The opening verse praises the Almighty, highli...  \n",
              "1   This verse suggests that a leader should not j...  \n",
              "2   It describes rain as the linchpin of the natur...  \n",
              "3   It extols the virtues of truthfulness and mora...  \n",
              "4   Discusses moderation in life and using resourc...  \n",
              "5   Highlights the importance of choosing friends ...  \n",
              "6   Advises rulers to be just and ethical to ensur...  \n",
              "7   Emphasizes the role of justice as foundational...  \n",
              "8   Celebrates the virtues of being a gracious hos...  \n",
              "9   Elevates patience as a virtue that underpins e...  \n",
              "10  Stresses the importance of learning from the w...  \n",
              "11  Warns about the destructive nature of anger, d...  \n",
              "12  Advocates for self-restraint and control over ...  \n",
              "13  Highlights the importance of expressing gratit...  \n",
              "14  Advocates for truth as a fundamental moral val...  \n",
              "15  Discusses the negative impacts of greed, leadi...  \n",
              "16  Discusses the virtues of benevolence and altru...  \n",
              "17  Explores the concept of karma, or actions and ...  \n",
              "18  Underlines the ethical responsibilities of lea...  \n",
              "19  Offers advice on prudent financial management ...  \n",
              "20  Links the acquisition of wealth to virtuous li...  \n",
              "21  Advocates for perseverance in the face of adve...  \n",
              "22  Offers guidance on resilience and mental stren...  \n",
              "23  Discusses ethical dilemmas and the importance ...  \n",
              "24  Provides insights on resolving conflicts throu...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-350bf9f4-041d-4471-963b-1ceb6d3e0ce4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Verse Number</th>\n",
              "      <th>Question</th>\n",
              "      <th>Label</th>\n",
              "      <th>Answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>What is the meaning of Thirukkural verse 1 and...</td>\n",
              "      <td>Meaning and Significance</td>\n",
              "      <td>The opening verse praises the Almighty, highli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>How does verse 5 of the Thirukkural address th...</td>\n",
              "      <td>Leadership</td>\n",
              "      <td>This verse suggests that a leader should not j...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>15</td>\n",
              "      <td>In what context does Thirukkural verse 15 disc...</td>\n",
              "      <td>Importance of Rain</td>\n",
              "      <td>It describes rain as the linchpin of the natur...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>25</td>\n",
              "      <td>What moral values are emphasized in verse 25 o...</td>\n",
              "      <td>Moral Values</td>\n",
              "      <td>It extols the virtues of truthfulness and mora...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>37</td>\n",
              "      <td>How does verse 37 relate to the contemporary i...</td>\n",
              "      <td>Sustainable Living</td>\n",
              "      <td>Discusses moderation in life and using resourc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>45</td>\n",
              "      <td>What advice does Thiruvalluvar offer about fri...</td>\n",
              "      <td>Friendship</td>\n",
              "      <td>Highlights the importance of choosing friends ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>60</td>\n",
              "      <td>Discuss the implications of verse 60 on the co...</td>\n",
              "      <td>Ruler Conduct</td>\n",
              "      <td>Advises rulers to be just and ethical to ensur...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>75</td>\n",
              "      <td>How does verse 75 of the Thirukkural address t...</td>\n",
              "      <td>Justice</td>\n",
              "      <td>Emphasizes the role of justice as foundational...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>85</td>\n",
              "      <td>What are the virtues extolled in verse 85 conc...</td>\n",
              "      <td>Hospitality</td>\n",
              "      <td>Celebrates the virtues of being a gracious hos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>90</td>\n",
              "      <td>How is the virtue of patience depicted in vers...</td>\n",
              "      <td>Patience</td>\n",
              "      <td>Elevates patience as a virtue that underpins e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>101</td>\n",
              "      <td>Interpret the meaning behind the advice given ...</td>\n",
              "      <td>Advice Interpretation</td>\n",
              "      <td>Stresses the importance of learning from the w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>110</td>\n",
              "      <td>Explain how verse 110 discusses the repercussi...</td>\n",
              "      <td>Repercussions of Anger</td>\n",
              "      <td>Warns about the destructive nature of anger, d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>125</td>\n",
              "      <td>What insights does verse 125 provide on the im...</td>\n",
              "      <td>Self-discipline</td>\n",
              "      <td>Advocates for self-restraint and control over ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>135</td>\n",
              "      <td>Discuss the role of gratitude as depicted in v...</td>\n",
              "      <td>Gratitude</td>\n",
              "      <td>Highlights the importance of expressing gratit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>145</td>\n",
              "      <td>How does verse 145 advocate for truthfulness?</td>\n",
              "      <td>Truthfulness</td>\n",
              "      <td>Advocates for truth as a fundamental moral val...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>150</td>\n",
              "      <td>What does verse 150 say about the consequences...</td>\n",
              "      <td>Greed Consequences</td>\n",
              "      <td>Discusses the negative impacts of greed, leadi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>165</td>\n",
              "      <td>Explain the philosophical underpinnings of ver...</td>\n",
              "      <td>Philosophical Underpinnings</td>\n",
              "      <td>Discusses the virtues of benevolence and altru...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>175</td>\n",
              "      <td>How does verse 175 enhance our understanding o...</td>\n",
              "      <td>Karma</td>\n",
              "      <td>Explores the concept of karma, or actions and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>180</td>\n",
              "      <td>What lesson on leadership can be drawn from ve...</td>\n",
              "      <td>Leadership</td>\n",
              "      <td>Underlines the ethical responsibilities of lea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>190</td>\n",
              "      <td>Analyze the advice on wealth management given ...</td>\n",
              "      <td>Wealth Management</td>\n",
              "      <td>Offers advice on prudent financial management ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>200</td>\n",
              "      <td>What does verse 200 teach us about the balance...</td>\n",
              "      <td>Wealth and Virtue</td>\n",
              "      <td>Links the acquisition of wealth to virtuous li...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>210</td>\n",
              "      <td>How does verse 210 address the theme of determ...</td>\n",
              "      <td>Determination</td>\n",
              "      <td>Advocates for perseverance in the face of adve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>220</td>\n",
              "      <td>Interpret the guidance provided in verse 220 o...</td>\n",
              "      <td>Dealing with Adversity</td>\n",
              "      <td>Offers guidance on resilience and mental stren...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>230</td>\n",
              "      <td>What ethical considerations are highlighted in...</td>\n",
              "      <td>Ethical Considerations</td>\n",
              "      <td>Discusses ethical dilemmas and the importance ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>240</td>\n",
              "      <td>How does verse 240 of the Thirukkural relate t...</td>\n",
              "      <td>Conflict Resolution</td>\n",
              "      <td>Provides insights on resolving conflicts throu...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-350bf9f4-041d-4471-963b-1ceb6d3e0ce4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-350bf9f4-041d-4471-963b-1ceb6d3e0ce4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-350bf9f4-041d-4471-963b-1ceb6d3e0ce4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-54ae0487-bff8-4b0c-bbb3-8331944d45cf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-54ae0487-bff8-4b0c-bbb3-8331944d45cf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-54ae0487-bff8-4b0c-bbb3-8331944d45cf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_7bb30db2-6d8d-4fb4-9fd9-07956a8e72d4\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('dataframe')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7bb30db2-6d8d-4fb4-9fd9-07956a8e72d4 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('dataframe');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataframe",
              "summary": "{\n  \"name\": \"dataframe\",\n  \"rows\": 25,\n  \"fields\": [\n    {\n      \"column\": \"Verse Number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 74,\n        \"min\": 1,\n        \"max\": 240,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          85,\n          165,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"What are the virtues extolled in verse 85 concerning hospitality?\",\n          \"Explain the philosophical underpinnings of verse 165 in the Thirukkural.\",\n          \"What is the meaning of Thirukkural verse 1 and its significance in Tamil literature?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          \"Hospitality\",\n          \"Philosophical Underpinnings\",\n          \"Meaning and Significance\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"Celebrates the virtues of being a gracious host, depicting hospitality as a moral obligation and a sign of good character.\",\n          \"Discusses the virtues of benevolence and altruism, encouraging actions that promote the welfare of others as a foundation for a virtuous life.\",\n          \"The opening verse praises the Almighty, highlighting the primacy of rain sourced from the waters governed by the divine. It sets the thematic tone of the text, emphasizing moral and ethical living under divine guidance, foundational in Tamil literature.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Formatting the Data"
      ],
      "metadata": {
        "id": "aAKBEnU7yDru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "formatted_data = []\n",
        "for question, answer in zip(questions, answers):\n",
        "    # Combine question and answer with special tokens\n",
        "    formatted_entry = f\"{question} <|answer|> {answer} <|endoftext|>\"\n",
        "    formatted_data.append(formatted_entry)\n"
      ],
      "metadata": {
        "id": "MxuiTPV0yIFl"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Tokenizing the Data"
      ],
      "metadata": {
        "id": "iqh-oE_2yPQs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "# Tokenize the formatted data\n",
        "tokenized_data = [tokenizer.encode(data_entry, add_special_tokens=True) for data_entry in formatted_data]\n"
      ],
      "metadata": {
        "id": "Uxrq2lGKyMQO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301,
          "referenced_widgets": [
            "b6b6c87ddb3b486fa60c37ba1b4d2b79",
            "3714c463d126490a89028869bd3ba178",
            "501ceb0eafff46018e62f8fbe1b64be9",
            "7efbb1509ab74e82a18f40e68d654684",
            "bdd4dd42e05d43f3b931a467b587f290",
            "03f75bb7629f4f2c925a857e706d1adf",
            "2b8db1532b8c42bab62275b79921359c",
            "bdf84429c4d346afbc0944ee06f8d19c",
            "3f90cfe350ea4d6ba6aaee840f3634cc",
            "c6fabdbac92f4af2a3f182d930b2adec",
            "5a8443d67fae43638325216826b1ac00",
            "411f4d2c5513454eaa260c4e541cfe6a",
            "ebc778c766494faabb9f8b88ee528df3",
            "7ebf055800654b0c905ba2eb868a48a4",
            "e840223e347c417a8c6b5b9ef0640201",
            "41ae4848894345f489a8c66750970c73",
            "4d6b2a46ae6a4f558ffb248ae4d511cf",
            "47b903dabd5a4f88932fd44f56e9e4d8",
            "83233900cf38415f82a3940e5bcce073",
            "526ce59d3a854e19b18c8a5141c1b199",
            "124c2565fa4048039e9a331e9f0740e3",
            "6169f5e6bbe647d4883c24f96d7df55b",
            "5bcb9b7c3f8c476ea7cbfbef62f30074",
            "aabd2d672c9b4d2cba7bc1a0e55849a1",
            "81af9b2221264a0a959b45d5e205a69f",
            "4fa7d4d5f3624575bf7d77c9ef4104d8",
            "99df569e635243d496a11ac85e3353fa",
            "1598488429f447fa81af77a3c597eeb8",
            "604f16ceb23a426c8c91d36e833c52fe",
            "76410e576bad4b278430b23eafd97de3",
            "a2c2b86a268e402986514b8c330deb16",
            "5b084d4cf2fa4d7d935576c688baf8c0",
            "bb6aac6f26d74aa3ac703c50e5fe9bb5",
            "10101b6fa5ed44dea8d1ae27fdc57f45",
            "d48b8251707940ed9b5368a960510abf",
            "9966fa4a82fc47ca90574dbd79f1a7d9",
            "4b10cb49442e443ab8705936bad6ad33",
            "baea41d9bd804d918481a4b275573268",
            "a082596f70a84fe3b633f6fa95ac3c2d",
            "ec9542fa50d94aaa87707f5e8c2caa5f",
            "c3061cc8ba354b5db007beffd1862211",
            "8293bc0440eb4fa0b3c3e618fbdf7886",
            "c5b5f3ee6fc64debbef6a7beff88da16",
            "f1ce7c787b9948eabd0e0dbef572aef1",
            "ceead07728cd4f909146eb8ce3ab586a",
            "016d6f0b03b34397b05c65ce5e8ce950",
            "e0e5ba5000a7494c9696c6dca6db9246",
            "228967fb4c2044bd821bb16ef8fab147",
            "f6586238189c4e55b764d437b83d13d8",
            "1b98a2f1cc8b4e02a1654b55f15e30c0",
            "0b4644bf7f144bf9a71b37e8119b81dc",
            "b994b5b65cef4d98b09d35691793903e",
            "ddb6ebea89b0437b87b86f806e1cec5d",
            "5a7cd89c94f442f59d1f1e3bcc70e1cd",
            "0d835c8e257b417c971f89ef9dc54ca4"
          ]
        },
        "outputId": "ad6a0c3e-fbb9-4a81-c6de-92a4cdb9c1d8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b6b6c87ddb3b486fa60c37ba1b4d2b79"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "411f4d2c5513454eaa260c4e541cfe6a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5bcb9b7c3f8c476ea7cbfbef62f30074"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10101b6fa5ed44dea8d1ae27fdc57f45"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ceead07728cd4f909146eb8ce3ab586a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Creating a Custom Dataset"
      ],
      "metadata": {
        "id": "388gcLvRyiTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "# Since GPT-2 does not have a pad token by default, we can use eos_token as the pad token.\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "\n",
        "# Function to tokenize and pad texts\n",
        "def tokenize_and_pad(text_list, max_length):\n",
        "    encodings = tokenizer(text_list, add_special_tokens=True, truncation=True, padding='max_length', max_length=max_length, return_tensors=\"pt\")\n",
        "    # Shift input_ids to the right to create labels\n",
        "    encodings['labels'] = encodings.input_ids.detach().clone()\n",
        "    return encodings\n",
        "\n",
        "\n",
        "# Create a dataset class for handling the encoded data\n",
        "class ThirukkuralDataset(Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Retrieve input_ids for the sample\n",
        "        input_ids = self.encodings['input_ids'][idx]\n",
        "        # Labels are usually shifted input_ids for language modeling\n",
        "        labels = input_ids.clone()  # Make a copy of input_ids to use as labels\n",
        "        return {'input_ids': input_ids, 'labels': labels, 'attention_mask': self.encodings['attention_mask'][idx]}\n",
        "\n",
        "\n",
        "\n",
        "# Prepare data for tokenizer\n",
        "formatted_data = [f\"{question} <|answer|> {answer} <|endoftext|>\" for question, answer in zip(questions, answers)]\n",
        "\n",
        "# Tokenize and pad the data\n",
        "encoded_inputs = tokenize_and_pad(formatted_data, max_length=512)  # Adjust max_length as needed\n",
        "\n",
        "# Create the dataset\n",
        "dataset = ThirukkuralDataset(encoded_inputs)\n",
        "\n",
        "# Setup DataLoader\n",
        "batch_size = 4\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Example usage of the DataLoader\n",
        "for batch in dataloader:\n",
        "    print(batch['input_ids'].shape)\n",
        "    print(batch['labels'].shape)  # Ensure labels are being correctly formed\n",
        "    print(batch['attention_mask'].shape)\n",
        "    break  # Break after printing the first batch\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6HDEURzz3W4",
        "outputId": "0fa209a2-833f-491c-d910-c5dc3e104aa3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 512])\n",
            "torch.Size([4, 512])\n",
            "torch.Size([4, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Assuming 'encoded_inputs' is your full dataset containing keys like 'input_ids' and 'attention_mask'\n",
        "input_ids_train, input_ids_val, attention_mask_train, attention_mask_val = train_test_split(\n",
        "    encoded_inputs['input_ids'], encoded_inputs['attention_mask'], test_size=0.1, random_state=42\n",
        ")\n",
        "\n",
        "# Reconstruct the train and validation sets\n",
        "train_encodings = {'input_ids': input_ids_train, 'attention_mask': attention_mask_train}\n",
        "val_encodings = {'input_ids': input_ids_val, 'attention_mask': attention_mask_val}\n",
        "\n",
        "# Now, wrap these in your dataset class\n",
        "train_dataset = ThirukkuralDataset(train_encodings)\n",
        "val_dataset = ThirukkuralDataset(val_encodings)\n"
      ],
      "metadata": {
        "id": "bfwYt_3rEDQc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, Trainer, TrainingArguments\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# Load a pre-trained GPT-2 model\n",
        "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # Output directory for model checkpoints\n",
        "    evaluation_strategy=\"epoch\",     # Evaluation is done at the end of each epoch\n",
        "    learning_rate=1e-5,              # Learning rate\n",
        "    per_device_train_batch_size=4,   # Batch size per device during training\n",
        "    per_device_eval_batch_size=4,    # Batch size per device during evaluation\n",
        "    num_train_epochs=4,              # Number of training epochs\n",
        "    weight_decay=0.1,               # Weight decay if applicable\n",
        "    logging_dir='./logs',            # Directory for storing logs\n",
        "    logging_steps=30,                # Log metrics every 10 steps\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Initialize the Trainer with both training and validation datasets\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset  # Include the validation dataset here\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649,
          "referenced_widgets": [
            "f11f45f57492409b94e0240b07221657",
            "ad05aa380ea44d948f98e9e0957722f0",
            "9249159280fb41d1bb3fbb9b88a15796",
            "0eee7a1982b34d549addb86b6d31ec42",
            "334c5c6bb15e407583e5f06e48ab8d74",
            "b85268c3763247fca29bf6ab1407579b",
            "ad6482b772a9491d88e9cadb0f9803bf",
            "f9f31a426fa24c9cac42a20b0b681823",
            "1bf7beb15e1e4458af8de3ffc0be1e0c",
            "4c3a64def99141cd94b131a8e6eeeb53",
            "6bb2a3357e414020af8f323598e329e9",
            "1ad369c8f9ee4620b50b60d67e1dca2e",
            "c8cb2a3ecee948d1aa72eab445e9e195",
            "90211dd768c7417e87621e15a682909f",
            "b6e2d9ea86f94fa8abe729ad3f97c91e",
            "2df45a6e7f7b4c2bbc70d16cf494f21c",
            "f901408bf9ff4339b04bdf97bfaf5b1e",
            "00015664204c4fb5a9fc03debf891a5e",
            "ed77dd2f6e0d41b28efdf077bca1394c",
            "e7be317c9e3545f48a8b892596b6bb2f",
            "dd6cbb64fc0d4121b64e7280ae72b373",
            "f915f2496e1340b7bbd0921f46c57937"
          ]
        },
        "id": "_jhHlcBd23Ir",
        "outputId": "04297b92-644f-4348-e3b0-aedfcd45699d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f11f45f57492409b94e0240b07221657"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1ad369c8f9ee4620b50b60d67e1dca2e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmsvarshini1703\u001b[0m (\u001b[33mmsvarshini1703-st-joseph-s-college-of-engineering-chennai\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250310_142724-mgy8aluw</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/msvarshini1703-st-joseph-s-college-of-engineering-chennai/huggingface/runs/mgy8aluw' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/msvarshini1703-st-joseph-s-college-of-engineering-chennai/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/msvarshini1703-st-joseph-s-college-of-engineering-chennai/huggingface' target=\"_blank\">https://wandb.ai/msvarshini1703-st-joseph-s-college-of-engineering-chennai/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/msvarshini1703-st-joseph-s-college-of-engineering-chennai/huggingface/runs/mgy8aluw' target=\"_blank\">https://wandb.ai/msvarshini1703-st-joseph-s-college-of-engineering-chennai/huggingface/runs/mgy8aluw</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [24/24 00:19, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>7.265726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.307821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.792470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.325166</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=24, training_loss=5.20257027943929, metrics={'train_runtime': 301.2118, 'train_samples_per_second': 0.292, 'train_steps_per_second': 0.08, 'total_flos': 22993698816000.0, 'train_loss': 5.20257027943929, 'epoch': 4.0})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Predictions"
      ],
      "metadata": {
        "id": "0kQbdb64GsNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)  # Make sure to move your model to the same device!\n"
      ],
      "metadata": {
        "id": "6PWYuOaMK2RE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba975e85-3293-4838-9bd3-1ba5135e05a8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 768)\n",
              "    (wpe): Embedding(1024, 768)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-11): 12 x GPT2Block(\n",
              "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D(nf=2304, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=768)\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D(nf=3072, nx=768)\n",
              "          (c_proj): Conv1D(nf=768, nx=3072)\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Assuming 'val_dataset' is already created and is available\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=16)\n",
        "\n",
        "model.eval()  # Set model to evaluation mode\n",
        "predictions = []\n",
        "labels = []\n",
        "\n",
        "for batch in val_dataloader:\n",
        "    input_ids = batch['input_ids'].to(device)\n",
        "    attention_mask = batch['attention_mask'].to(device)\n",
        "    labels += batch['labels'].tolist()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        preds = torch.argmax(outputs.logits, dim=-1).cpu().numpy()\n",
        "        predictions.extend(preds)\n",
        "\n",
        "# Flatten lists if predictions and labels are not flat (depends on model and data)\n",
        "predictions = [p for sublist in predictions for p in sublist]\n",
        "labels = [l for sublist in labels for l in sublist]\n"
      ],
      "metadata": {
        "id": "ag5LcMB5GheE"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Convert class weights from dictionary values to a list\n",
        "# class_weights_list = list(class_weights_dict.values())\n",
        "\n",
        "# # Convert the list to a tensor\n",
        "# class_weights_tensor = torch.tensor(class_weights_list, dtype=torch.float).to(device)\n",
        "\n",
        "# # Use this tensor in the loss function (if using CrossEntropyLoss for classification)\n",
        "# loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights_tensor)\n"
      ],
      "metadata": {
        "id": "NPIBZubENE-z"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Assuming 'labels' is a list of all your labels\n",
        "# classes = np.unique(labels)  # Extract unique classes\n",
        "\n",
        "# # Compute class weights for these unique classes\n",
        "# class_weights = compute_class_weight('balanced', classes=classes, y=labels)\n",
        "\n",
        "# # Create a dictionary mapping class index to weight\n",
        "# class_weights_dict = {classes[i]: class_weights[i] for i in range(len(classes))}\n",
        "\n",
        "# # If you have non-sequential class labels, make sure they match with your model's output layer\n"
      ],
      "metadata": {
        "id": "GsJtOGgoNKxL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compute Precision, Recall, and F1-Score"
      ],
      "metadata": {
        "id": "4oW8kU1nLBqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "print(\"Label distribution in predictions:\", Counter(predictions))\n",
        "print(\"Label distribution in true labels:\", Counter(labels))\n"
      ],
      "metadata": {
        "id": "M6Z3FQ8cL2Ku",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b69e9c25-fdbf-41c3-9477-0445f102fc9a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label distribution in predictions: Counter({198: 1112, 464: 161, 50256: 107, 262: 29, 286: 12, 290: 12, 13: 12, 29: 8, 30: 4, 318: 3, 257: 3, 1266: 2, 416: 2, 922: 2, 1279: 2, 1849: 2, 4732: 2, 20283: 2, 3099: 2, 3616: 2, 284: 2, 4453: 2, 383: 2, 692: 1, 276: 1, 642: 1, 378: 1, 27494: 1, 33362: 1, 2583: 1, 11: 1, 355: 1, 1611: 1, 835: 1, 481: 1, 3450: 1, 79: 1, 3732: 1, 654: 1, 343: 1, 71: 1, 17580: 1, 10396: 1, 594: 1, 1042: 1, 326: 1, 389: 1, 9490: 1, 880: 1, 1724: 1, 329: 1, 1365: 1, 1204: 1, 27193: 1, 849: 1, 338: 1, 25: 1, 362: 1, 46917: 1, 536: 1, 366: 1, 1793: 1, 1109: 1, 1590: 1, 422: 1, 3800: 1, 1512: 1, 1621: 1, 8557: 1, 3815: 1, 11154: 1, 3968: 1})\n",
            "Label distribution in true labels: Counter({50256: 1370, 262: 13, 286: 8, 91: 6, 257: 5, 11: 5, 13: 5, 287: 4, 18527: 4, 290: 4, 27494: 3, 1279: 3, 41484: 3, 29: 3, 220: 3, 2061: 2, 33362: 2, 30: 2, 355: 2, 6573: 2, 739: 2, 536: 2, 343: 2, 2724: 2, 74: 2, 1523: 2, 32519: 2, 9285: 2, 11871: 2, 389: 1, 1070: 1, 692: 1, 276: 1, 7600: 1, 9305: 1, 28921: 1, 689: 1, 852: 1, 43210: 1, 2583: 1, 27561: 1, 12990: 1, 1051: 1, 922: 1, 2095: 1, 18438: 1, 391: 1, 17580: 1, 79: 1, 3732: 1, 654: 1, 21409: 1, 36691: 1, 274: 1, 10004: 1, 10396: 1, 594: 1, 37677: 1, 1042: 1, 12577: 1, 4028: 1, 326: 1, 7719: 1, 9490: 1, 1854: 1, 8489: 1, 329: 1, 41276: 1, 1204: 1, 318: 1, 3616: 1, 352: 1, 663: 1, 12085: 1, 383: 1, 4756: 1, 40221: 1, 33987: 1, 21292: 1, 2684: 1, 1590: 1, 6290: 1, 18229: 1, 422: 1, 10150: 1, 21825: 1, 416: 1, 632: 1, 5621: 1, 606: 1, 1512: 1, 8216: 1, 2420: 1, 36360: 1, 15028: 1, 2877: 1, 11154: 1, 43936: 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "precision = precision_score(labels, predictions, average='macro')\n",
        "recall = recall_score(labels, predictions, average='macro')\n",
        "f1 = f1_score(labels, predictions, average='macro')\n",
        "\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1-Score: {f1}\")\n"
      ],
      "metadata": {
        "id": "g5l3uTKyLEYy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b43b911-b3a8-458f-e78b-9f6fa455c1ce"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.007633587786259542\n",
            "Recall: 0.0005961999219925336\n",
            "F1-Score: 0.001106017458537266\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('./my_trained_model')\n"
      ],
      "metadata": {
        "id": "HLmhOqLPNcdy"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# QUERY DETAILS GPT2"
      ],
      "metadata": {
        "id": "q3DwrcYLVQ1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def extract_query_details(query):\n",
        "    query = query.lower()\n",
        "    details = {\n",
        "        'query_type': None,\n",
        "        'query_value': None,\n",
        "        'translate_to': 'en' if 'in english' in query else None,\n",
        "        'author_alias': None,\n",
        "        'detail': None\n",
        "    }\n",
        "\n",
        "    # Adjusting to match the structure needed to extract the kural number\n",
        "    match = re.search(r'kural number (\\d+)', query)\n",
        "    if match:\n",
        "        details['query_type'] = 'kural_number'\n",
        "        details['query_value'] = int(match.group(1))\n",
        "\n",
        "    return details\n",
        "\n",
        "\n",
        "\n",
        "    # Define the Thirukkural response function\n",
        "     # Define the function to get responses based on Thirukkural\n",
        "\n",
        "\n",
        "def get_thirukkural_response(kural_data, query_type, query_value, translate_to=None, author_alias=None, detail=None):\n",
        "    \"\"\"Retrieve a Thirukkural response based on query type, value, and optional author explanation.\"\"\"\n",
        "    translator = googletrans.Translator()\n",
        "    responses = []\n",
        "    author_map = {\n",
        "        'mu_va': 'ta_mu_va',\n",
        "        'mu va': 'ta_mu_va',\n",
        "        'ta_mu_va': 'ta_mu_va',\n",
        "        'salamon': 'ta_salamon',\n",
        "        'ta_salamon': 'ta_salamon',\n",
        "        'சாலமன் பாப்பையா': 'ta_salamon'\n",
        "    }\n",
        "\n",
        "\n",
        "    # Helper function to perform translation\n",
        "    def translate(text, target_lang):\n",
        "        \"\"\"Translate text using Google Translate.\"\"\"\n",
        "        if target_lang:\n",
        "            try:\n",
        "                return translator.translate(text, src='ta' if target_lang == 'en' else 'en', dest=target_lang).text\n",
        "            except Exception as e:\n",
        "                print(f\"Translation failed: {e}\")\n",
        "                return text\n",
        "        return text\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Identify kurals based on query_type\n",
        "    kurals_to_process = []\n",
        "    if query_type == 'section_name':\n",
        "        kurals_to_process = [k for k in kural_data['kurals'] if k['section'] == query_value]\n",
        "    elif query_type == 'chapter_name':\n",
        "        kurals_to_process = [k for k in kural_data['kurals'] if k['chapter'] == query_value]\n",
        "    elif query_type in ['keyword', 'starts_with', 'ends_with']:\n",
        "        for kural in kural_data['kurals']:\n",
        "            if (query_type == 'keyword' and query_value in ' '.join(kural['kural']).lower()) or \\\n",
        "               (query_type == 'starts_with' and kural['kural'][0].startswith(query_value)) or \\\n",
        "               (query_type == 'ends_with' and kural['kural'][-1].endswith(query_value)):\n",
        "                kurals_to_process.append(kural)\n",
        "\n",
        "    # Generate responses for each kural\n",
        "    for kural in kurals_to_process:\n",
        "        kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "        if translate_to == 'ta':\n",
        "            english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "            translated_text = translate(english_meaning, 'en', 'ta')\n",
        "            responses.append(f\"{kural_text}\\nMeaning (Tamil): {translated_text}\")\n",
        "        elif author_alias and author_alias in author_map:\n",
        "            author_key = author_map[author_alias]\n",
        "            explanation = kural['meaning'].get(author_key, \"No explanation available.\")\n",
        "            if translate_to == 'en':\n",
        "                translated_text = translate(explanation, 'ta', 'en')\n",
        "                responses.append(f\"{kural_text}\\nExplanation by {author_alias} (English): {translated_text}\")\n",
        "            else:\n",
        "                responses.append(f\"{kural_text}\\nExplanation by {author_alias}: {explanation}\")\n",
        "        else:\n",
        "            english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "            responses.append(f\"{kural_text}\\nMeaning (English): {english_meaning}\")\n",
        "\n",
        "\n",
        "\n",
        "    # Define a function to format the response for kurals\n",
        "    def format_kural_response(kural):\n",
        "        \"\"\"Format the response for a single kural with optional translation or explanation.\"\"\"\n",
        "        kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "        if author_alias and author_alias in author_map:\n",
        "            author_key = author_map[author_alias]\n",
        "            explanation = kural['meaning'].get(author_key, \"No explanation available.\")\n",
        "            if translate_to:\n",
        "                explanation = translate(explanation, translate_to)\n",
        "            response = f\"{kural_text}\\nExplanation by {author_key.replace('ta_', '')}: {explanation}\"\n",
        "        elif translate_to:\n",
        "            english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "            translated_meaning = translate(english_meaning, translate_to)\n",
        "            response = f\"{kural_text}\\nMeaning ({translate_to.capitalize()}): {translated_meaning}\"\n",
        "        else:\n",
        "            english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "            response = f\"{kural_text}\\nMeaning (English): {english_meaning}\"\n",
        "        return response\n",
        "\n",
        "\n",
        "        # Rule 1 & 2: Section and/or Chapter based queries\n",
        "    if query_type in ['section_name', 'chapter_name']:\n",
        "        for kural in kural_data['kurals']:\n",
        "            if (query_type == 'section_name' and kural['section'] == query_value) or \\\n",
        "               (query_type == 'chapter_name' and kural['chapter'] == query_value):\n",
        "                kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "                if author_alias and author_alias in author_map:\n",
        "                    author_key = author_map[author_alias]\n",
        "                    explanation = kural['meaning'].get(author_key, \"No explanation available.\")\n",
        "                    kural_text += f\"\\nExplanation by {author_key}: {explanation}\"\n",
        "                else:\n",
        "                    kural_text += f\"\\nMeaning (English): {kural['meaning']['en']}\"\n",
        "                responses.append(kural_text)\n",
        "\n",
        "    # Rule 3, 9: Keyword based English meanings\n",
        "    if query_type == 'keyword':\n",
        "        kurals_by_keyword = [kural for kural in kural_data['kurals'] if query_value in ' '.join(kural['kural']).lower()]\n",
        "        if detail == 'english_meaning':\n",
        "            responses.extend([f\"Kural {k['number']}: {' '.join(k['kural'])}\\nMeaning (English): {k['meaning']['en']}\" for k in kurals_by_keyword])\n",
        "        elif detail == 'chapter_list':\n",
        "            chapters = set(k['chapter'] for k in kurals_by_keyword)\n",
        "            responses.extend(list(chapters))\n",
        "        else:\n",
        "            for kural in kurals_by_keyword:\n",
        "                if author_alias in author_map:\n",
        "                    kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "                    author_key = author_map[author_alias]\n",
        "                    explanation = kural['meaning'].get(author_key, \"No explanation available.\")\n",
        "                    responses.append(f\"{kural_text}\\nExplanation by {author_key}: {explanation}\")\n",
        "\n",
        "    # Rule 7, 8, 13, 14: Kurals starting/ending with a specific word\n",
        "    if query_type == 'starts_with':\n",
        "        responses.extend([f\"Kural {k['number']}: {' '.join(k['kural'])}\" for k in kural_data['kurals'] if k['kural'][0].startswith(query_value)])\n",
        "    if query_type == 'ends_with':\n",
        "        responses.extend([f\"Kural {k['number']}: {' '.join(k['kural'])}\" for k in kural_data['kurals'] if k['kural'][-1].endswith(query_value)])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Fetch by kural number\n",
        "    if query_type == 'kural_number':\n",
        "        kural_match = next((k for k in kural_data['kurals'] if k['number'] == int(query_value)), None)\n",
        "        if kural_match:\n",
        "            kural_text = f\"Kural {kural_match['number']}: {' '.join(kural_match['kural'])}\"\n",
        "            if author_alias and author_alias in author_map:\n",
        "                author_key = author_map[author_alias]\n",
        "                author_explanation = kural_match['meaning'].get(author_key, \"No explanation available for this author.\")\n",
        "                responses.append(f\"{kural_text}\\nExplanation by {author_key.replace('ta_', '')}: {author_explanation}\")\n",
        "            else:\n",
        "                english_meaning = kural_match['meaning'].get('en', \"No English translation available.\")\n",
        "                responses.append(f\"{kural_text}\\nMeaning (English): {english_meaning}\")\n",
        "\n",
        "    # Fetch by chapter name\n",
        "    elif query_type == 'chapter_name':\n",
        "        kurals_in_chapter = [k for k in kural_data['kurals'] if k['chapter'].lower() == query_value.lower()]\n",
        "        for kural in kurals_in_chapter:\n",
        "            kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "            if author_alias and author_alias in author_map:\n",
        "                author_key = author_map[author_alias]\n",
        "                explanation = kural['meaning'].get(author_key, \"No explanation available.\")\n",
        "                responses.append(f\"{kural_text}\\nExplanation by {author_key.replace('ta_', '')}: {explanation}\")\n",
        "            else:\n",
        "                english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "                responses.append(f\"{kural_text}\\nMeaning (English): {english_meaning}\")\n",
        "\n",
        "    # Fetch by section name\n",
        "    elif query_type == 'section_name':\n",
        "        chapters_in_section = set(k['chapter'] for k in kural_data['kurals'] if k['section'].lower() == query_value.lower())\n",
        "        for chapter in chapters_in_section:\n",
        "            kurals_in_chapter = [k for k in kural_data['kurals'] if k['chapter'].lower() == chapter.lower()]\n",
        "            chapter_responses = []\n",
        "            for kural in kurals_in_chapter:\n",
        "                kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "                english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "                chapter_responses.append(f\"{kural_text}\\nMeaning (English): {english_meaning}\")\n",
        "            responses.append(f\"Chapter: {chapter}\\n\" + \"\\n\".join(chapter_responses))\n",
        "\n",
        "\n",
        "                # Fetch by keyword in kural, which checks for keywords in the text of the kural\n",
        "    elif query_type == 'keyword':\n",
        "        kurals_by_keyword = [kural for kural in kural_data['kurals'] if query_value in \" \".join(kural['kural']).lower()]\n",
        "        for kural in kurals_by_keyword:\n",
        "            kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "            if author_alias and author_alias in author_map:\n",
        "                author_key = author_map[author_alias]\n",
        "                explanation = kural['meaning'].get(author_key, \"No explanation available.\")\n",
        "                responses.append(f\"{kural_text}\\nExplanation by {author_key.replace('ta_', '')}: {explanation}\")\n",
        "            else:\n",
        "                english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "                responses.append(f\"{kural_text}\\nMeaning (English): {english_meaning}\")\n",
        "\n",
        "\n",
        "# Logic to handle different types of queries\n",
        "    elif query_type == 'keyword':\n",
        "        if detail == 'starts_with':\n",
        "            kurals_filtered = [kural for kural in kural_data['kurals'] if kural['kural'][0].startswith(query_value)]\n",
        "        elif detail == 'ends_with':\n",
        "            kurals_filtered = [kural for kural in kural_data['kurals'] if kural['kural'][-1].endswith(query_value)]\n",
        "        for kural in kurals_filtered:\n",
        "            kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "            responses.append(kural_text)\n",
        "\n",
        "    elif query_type == 'author_translation':\n",
        "        kurals_filtered = [kural for kural in kural_data['kurals'] if author_alias in kural['meaning']]\n",
        "        for kural in kurals_filtered:\n",
        "            explanation = kural['meaning'][author_alias]\n",
        "            kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\\nExplanation by {author_alias}: {explanation}\"\n",
        "            responses.append(kural_text)\n",
        "\n",
        "    elif query_type == 'chapter_count':\n",
        "        count = sum(1 for kural in kural_data['kurals'] if kural['chapter'] == query_value)\n",
        "        responses.append(f\"Total kurals in chapter '{query_value}': {count}\")\n",
        "\n",
        "    # Check for the correct handling of the 'author_translation' query type\n",
        "    elif query_type == 'author_translation':\n",
        "        # Assuming query_value should be something like 'ta_mu_va'\n",
        "        kurals_filtered = [kural for kural in kural_data['kurals'] if query_value in kural['meaning']]\n",
        "        for kural in kurals_filtered:\n",
        "            explanation = kural['meaning'].get(query_value)\n",
        "            if explanation:  # Ensure there's a translation available\n",
        "                kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\\nExplanation by {query_value}: {explanation}\"\n",
        "                responses.append(kural_text)\n",
        "\n",
        "\n",
        "\n",
        "    # Fetch kurals that start or end with a specific word\n",
        "    elif query_type == 'starts_with' or query_type == 'ends_with':\n",
        "        kurals_filtered = [\n",
        "            kural for kural in kural_data['kurals']\n",
        "            if (query_type == 'starts_with' and kural['kural'][0].startswith(query_value)) or\n",
        "               (query_type == 'ends_with' and kural['kural'][1].endswith(query_value))\n",
        "        ]\n",
        "        for kural in kurals_filtered:\n",
        "            kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "            english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "            responses.append(f\"{kural_text}\\nMeaning (English): {english_meaning}\")\n",
        "\n",
        "            # Fetch kurals containing a keyword with different requirements\n",
        "    elif query_type == 'keyword':\n",
        "        filtered_kurals = [kural for kural in kural_data['kurals'] if query_value in \" \".join(kural['kural']).lower()]\n",
        "        if detail == 'chapter_list':\n",
        "            # List chapters that contain the keyword\n",
        "            chapter_set = set(kural['chapter'] for kural in filtered_kurals)\n",
        "            responses = list(chapter_set)\n",
        "        elif detail in ['mu_va', 'ta_salamon']:\n",
        "            # Show kural and explanation by the specific author for the keyword\n",
        "            for kural in filtered_kurals:\n",
        "                kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "                author_explanation = kural['meaning'].get(detail, \"No explanation available.\")\n",
        "                responses.append(f\"{kural_text}\\nExplanation by {detail}: {author_explanation}\")\n",
        "        elif detail == 'starts_with':\n",
        "            # Kurals that start with the specific word\n",
        "            responses = [f\"Kural {k['number']}: {' '.join(k['kural'])}\" for k in filtered_kurals if k['kural'][0].startswith(query_value)]\n",
        "        elif detail == 'ends_with':\n",
        "            # Kurals that end with the specific word\n",
        "            responses = [f\"Kural {k['number']}: {' '.join(k['kural'])}\" for k in filtered_kurals if k['kural'][1].endswith(query_value)]\n",
        "        else:\n",
        "            # Default to showing English translation only\n",
        "            for kural in filtered_kurals:\n",
        "                kural_text = f\"Kural {kural['number']}: {' '.join(kural['kural'])}\"\n",
        "                english_meaning = kural['meaning'].get('en', \"No English translation available.\")\n",
        "                responses.append(f\"{kural_text}\\nMeaning (English): {english_meaning}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return \"\\n\".join(responses) if responses else \"No Kural found matching the query.\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Call the response function with the extracted details\n",
        "    return get_thirukkural_response(**details)\n",
        "\n",
        "# Load the JSON file\n",
        "with open(\"/content/thirukural_git (1).json\", \"r\") as file:\n",
        "    kural_data = json.load(file)\n",
        "\n",
        "# Example usage\n",
        "query = \"What is the meaning of Kural number 5 in English?\"\n",
        "details = extract_query_details(query)\n",
        "response = get_thirukkural_response(kural_data, **details)\n",
        "print(response)\n"
      ],
      "metadata": {
        "id": "Miug2Ccdjo-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1791344b-104d-40b8-caa6-26fdba2328ce"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kural 5: இருள்சேர் இருவினையும் சேரா இறைவன் பொருள்சேர் புகழ்புரிந்தார் மாட்டு.\n",
            "Meaning (English): The two-fold deeds that spring from darkness shall not adhere to those who delight in the true praise of God.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dispatcher Fuction GPT2"
      ],
      "metadata": {
        "id": "kvWXTfIf7h2J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Assuming the functions get_thirukkural_response and extract_query_details are defined as before\n",
        "\n",
        "def dispatcher(query, kural_data):\n",
        "    details = extract_query_details(query)\n",
        "\n",
        "    # Rule-based criteria: If the query details extracted match specific types that the rule-based system can handle\n",
        "    if details['query_type'] in ['kural_number', 'section_name', 'chapter_name']:\n",
        "        return get_thirukkural_response(kural_data, **details)\n",
        "    else:\n",
        "        # If the query doesn't fit the rule-based system or requires more sophisticated understanding\n",
        "        return handle_ai_based(query)\n",
        "\n",
        "\n",
        "def handle_ai_based(query):\n",
        "    # Load the model and tokenizer\n",
        "    model = GPT2LMHeadModel.from_pretrained('./my_trained_model')\n",
        "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "    # Set padding token and adjust padding side for decoder-only architectures\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    tokenizer.padding_side = 'left'\n",
        "\n",
        "    # Encode the inputs\n",
        "    inputs = tokenizer.encode_plus(\n",
        "        query,\n",
        "        return_tensors=\"pt\",\n",
        "        add_special_tokens=True,\n",
        "        max_length=50,\n",
        "        padding='max_length',\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "    # Generate response using adjusted generation settings\n",
        "    outputs = model.generate(\n",
        "        inputs['input_ids'],\n",
        "        attention_mask=inputs['attention_mask'],\n",
        "        max_length=100,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        temperature=0.9,   # Slightly higher temperature for more variety\n",
        "        top_k=50,          # Limits the choices to the top 50 words\n",
        "        top_p=0.95,        # Uses cumulative probability to limit choices\n",
        "        no_repeat_ngram_size=2  # Prevents repeating the same 2-grams\n",
        "    )\n",
        "\n",
        "    # Decode the output\n",
        "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "# Load the kural data (assuming it's stored in a JSON file as before)\n",
        "with open(\"/content/thirukural_git (1).json\", \"r\") as file:\n",
        "    kural_data = json.load(file)\n",
        "\n",
        "# Example usage\n",
        "query = \"What is the meaning of Kural number 5 in English?\"\n",
        "response = dispatcher(query, kural_data)\n",
        "print(response)\n",
        "\n",
        "query = \"What is  Thirukkural\"\n",
        "response = dispatcher(query, kural_data)\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2q4cE4c42WUI",
        "outputId": "e69d24bf-83c8-438e-ee1e-45e85c91d02d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kural 5: இருள்சேர் இருவினையும் சேரா இறைவன் பொருள்சேர் புகழ்புரிந்தார் மாட்டு.\n",
            "Meaning (English): The two-fold deeds that spring from darkness shall not adhere to those who delight in the true praise of God.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:629: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/configuration_utils.py:634: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.95` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is  Thirukkural?\n",
            "\n",
            "Thirkur is a Sanskrit word meaning \"to be in the right place\". It is used in Sanskrit as a noun, and in English as an adjective.\n",
            ". It means \"in the wrong place\" or \"on the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT-4\n"
      ],
      "metadata": {
        "id": "CIGnvHPTXEnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "api_key = getpass('Enter your OpenAI API key: ')\n",
        "openai.api_key = api_key\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aGnnaaGciwj",
        "outputId": "d4fc5471-8006-4997-af28-fdabb2448e14"
      },
      "execution_count": 22,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B3p_Bg32eE6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL TRAINING & DISPATCHER GPT 3.5"
      ],
      "metadata": {
        "id": "obo0rcl7Ksax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load the kural data\n",
        "def load_kural_data(file_path):\n",
        "    with open(file_path, 'r') as file:\n",
        "        return json.load(file)"
      ],
      "metadata": {
        "id": "VdY46pANyYzl"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to handle AI-based interactions using GPT-4\n",
        "def handle_ai_based(query):\n",
        "\n",
        "\n",
        "    try:\n",
        "        # Setup for the chat completion call\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo-0125\",\n",
        "\n",
        "\n",
        "\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a chatbot trained to answer questions about Thirukkural.You are an AI trained extensively on the Thirukkural, capable of understanding and responding in Tamil, English, and Tanglish.You have detailed knowledge of the commentaries by Mu. Varadarasanar and Salamon Pappaiya on the Thirukkural verses.You can provide explanations, interpret meanings, and relate verses to modern contexts as per the commentators' insights.\"},\n",
        "                {\"role\": \"user\", \"content\": query}\n",
        "            ],\n",
        "            temperature=0.7,\n",
        "            max_tokens=300\n",
        "        )\n",
        "        return response['choices'][0]['message']['content']\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {str(e)}\"\n",
        "\n",
        "def dispatcher(query, kural_data):\n",
        "    details = extract_query_details(query)\n",
        "\n",
        "    if details['query_type'] == 'kural_number' and 'kural_number' in details:\n",
        "        return get_thirukkural_response(kural_data, 'kural_number', details['kural_number'])\n",
        "    elif details['query_type'] == 'chapter_name' and 'chapter_name' in details:\n",
        "        return get_thirukkural_response(kural_data, 'chapter_name', details['chapter_name'])\n",
        "    else:\n",
        "        return handle_ai_based(query)\n",
        "\n",
        "\n",
        "def extract_query_details(query):\n",
        "    \"\"\"\n",
        "    Extracts details from the user's query. Attempts to determine the type of query\n",
        "    and extract relevant parameters such as the kural number.\n",
        "    \"\"\"\n",
        "    query = query.lower()\n",
        "    # Regular expression to find numeric patterns after 'kural number'\n",
        "    match = re.search(r\"kural number (\\d+)\", query)\n",
        "    if match:\n",
        "        return {'query_type': 'kural_number', 'kural_number': int(match.group(1))}\n",
        "\n",
        "    # Assuming 'chapter name' or 'section name' might also be part of the input\n",
        "    chapter_match = re.search(r\"chapter name (\\w+)\", query)\n",
        "    if chapter_match:\n",
        "        return {'query_type': 'chapter_name', 'chapter_name': chapter_match.group(1)}\n",
        "\n",
        "    # If the input does not match any known pattern\n",
        "    return {'query_type': 'free_text', 'query': query}\n",
        "\n",
        "# Assuming the rest of your functions and loading mechanisms are defined as in your previous examples\n",
        "\n",
        "\n",
        "# Load Thirukkural data\n",
        "kural_data = load_kural_data(\"/content/thirukural_git (1).json\")\n",
        "\n",
        "# Test the dispatcher\n",
        "query = \"What is the meaning of Kural number 5 in English?\"\n",
        "response = dispatcher(query, kural_data)\n",
        "print(response)\n",
        "\n",
        "query = \"How can Thirukkural apply to modern world friendship by MU VA?\"\n",
        "response = dispatcher(query, kural_data)\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwlMniptKwov",
        "outputId": "adadeeb0-e61c-451d-f91f-7a09fc558b85"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kural 5: இருள்சேர் இருவினையும் சேரா இறைவன் பொருள்சேர் புகழ்புரிந்தார் மாட்டு.\n",
            "Meaning (English): The two-fold deeds that spring from darkness shall not adhere to those who delight in the true praise of God.\n",
            "An error occurred: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL TRAINING & DISPATCHER GPT4"
      ],
      "metadata": {
        "id": "v9T5R2KWTaKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT-4"
      ],
      "metadata": {
        "id": "rDcqqMNIxoQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to handle AI-based interactions using GPT-4\n",
        "def handle_ai_based(query):\n",
        "\n",
        "\n",
        "    try:\n",
        "        # Setup for the chat completion call\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4\",\n",
        "\n",
        "\n",
        "\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a chatbot trained to answer questions about Thirukkural.You are an AI trained extensively on the Thirukkural, capable of understanding and responding in Tamil, English, and Tanglish.You have detailed knowledge of the commentaries by Mu. Varadarasanar and Salamon Pappaiya on the Thirukkural verses.You can provide explanations, interpret meanings, and relate verses to modern contexts as per the commentators' insights.\"},\n",
        "                {\"role\": \"user\", \"content\": query}\n",
        "            ],\n",
        "            temperature=0.7,\n",
        "            max_tokens=300\n",
        "        )\n",
        "        return response['choices'][0]['message']['content']\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {str(e)}\"\n",
        "\n",
        "def dispatcher(query, kural_data):\n",
        "    details = extract_query_details(query)\n",
        "\n",
        "    if details['query_type'] == 'kural_number' and 'kural_number' in details:\n",
        "        return get_thirukkural_response(kural_data, 'kural_number', details['kural_number'])\n",
        "    elif details['query_type'] == 'chapter_name' and 'chapter_name' in details:\n",
        "        return get_thirukkural_response(kural_data, 'chapter_name', details['chapter_name'])\n",
        "    else:\n",
        "        return handle_ai_based(query)\n",
        "\n",
        "\n",
        "def extract_query_details(query):\n",
        "    \"\"\"\n",
        "    Extracts details from the user's query. Attempts to determine the type of query\n",
        "    and extract relevant parameters such as the kural number.\n",
        "    \"\"\"\n",
        "    query = query.lower()\n",
        "    # Regular expression to find numeric patterns after 'kural number'\n",
        "    match = re.search(r\"kural number (\\d+)\", query)\n",
        "    if match:\n",
        "        return {'query_type': 'kural_number', 'kural_number': int(match.group(1))}\n",
        "\n",
        "    # Assuming 'chapter name' or 'section name' might also be part of the input\n",
        "    chapter_match = re.search(r\"chapter name (\\w+)\", query)\n",
        "    if chapter_match:\n",
        "        return {'query_type': 'chapter_name', 'chapter_name': chapter_match.group(1)}\n",
        "\n",
        "    # If the input does not match any known pattern\n",
        "    return {'query_type': 'free_text', 'query': query}\n",
        "\n",
        "# Assuming the rest of your functions and loading mechanisms are defined as in your previous examples\n",
        "\n",
        "\n",
        "# Load Thirukkural data\n",
        "kural_data = load_kural_data(\"/content/thirukural_git (1).json\")\n",
        "\n",
        "# Test the dispatcher\n",
        "query = \"What is the meaning of Kural number 5 in English?\"\n",
        "response = dispatcher(query, kural_data)\n",
        "print(response)\n",
        "\n",
        "query = \"How can Thirukkural apply to modern world friendship by MU VA?\"\n",
        "response = dispatcher(query, kural_data)\n",
        "print(response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ep6gsqO_tnW",
        "outputId": "357799e6-f9e6-471c-b812-ccf2b4845d9f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kural 5: இருள்சேர் இருவினையும் சேரா இறைவன் பொருள்சேர் புகழ்புரிந்தார் மாட்டு.\n",
            "Meaning (English): The two-fold deeds that spring from darkness shall not adhere to those who delight in the true praise of God.\n",
            "An error occurred: The model `gpt-4` does not exist or you do not have access to it.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT-4o"
      ],
      "metadata": {
        "id": "V6d4nhDxxe7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to handle AI-based interactions using GPT-4\n",
        "def handle_ai_based(query):\n",
        "\n",
        "\n",
        "    try:\n",
        "        # Setup for the chat completion call\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-4o-2024-05-13\",\n",
        "\n",
        "\n",
        "\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a chatbot trained to answer questions about Thirukkural.You are an AI trained extensively on the Thirukkural, capable of understanding and responding in Tamil, English, and Tanglish.You have detailed knowledge of the commentaries by Mu. Varadarasanar and Salamon Pappaiya on the Thirukkural verses.You can provide explanations, interpret meanings, and relate verses to modern contexts as per the commentators' insights.\"},\n",
        "                {\"role\": \"user\", \"content\": query}\n",
        "            ],\n",
        "            temperature=0.7,\n",
        "            max_tokens=300\n",
        "        )\n",
        "        return response['choices'][0]['message']['content']\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {str(e)}\"\n",
        "\n",
        "def dispatcher(query, kural_data):\n",
        "    details = extract_query_details(query)\n",
        "\n",
        "    if details['query_type'] == 'kural_number' and 'kural_number' in details:\n",
        "        return get_thirukkural_response(kural_data, 'kural_number', details['kural_number'])\n",
        "    elif details['query_type'] == 'chapter_name' and 'chapter_name' in details:\n",
        "        return get_thirukkural_response(kural_data, 'chapter_name', details['chapter_name'])\n",
        "    else:\n",
        "        return handle_ai_based(query)\n",
        "\n",
        "\n",
        "def extract_query_details(query):\n",
        "    \"\"\"\n",
        "    Extracts details from the user's query. Attempts to determine the type of query\n",
        "    and extract relevant parameters such as the kural number.\n",
        "    \"\"\"\n",
        "    query = query.lower()\n",
        "    # Regular expression to find numeric patterns after 'kural number'\n",
        "    match = re.search(r\"kural number (\\d+)\", query)\n",
        "    if match:\n",
        "        return {'query_type': 'kural_number', 'kural_number': int(match.group(1))}\n",
        "\n",
        "    # Assuming 'chapter name' or 'section name' might also be part of the input\n",
        "    chapter_match = re.search(r\"chapter name (\\w+)\", query)\n",
        "    if chapter_match:\n",
        "        return {'query_type': 'chapter_name', 'chapter_name': chapter_match.group(1)}\n",
        "\n",
        "    # If the input does not match any known pattern\n",
        "    return {'query_type': 'free_text', 'query': query}\n",
        "\n",
        "# Assuming the rest of your functions and loading mechanisms are defined as in your previous examples\n",
        "\n",
        "\n",
        "# Load Thirukkural data\n",
        "kural_data = load_kural_data(\"/content/thirukural_git (1).json\")\n",
        "\n",
        "# Test the dispatcher\n",
        "query = \"What is the meaning of Kural number 5 in English?\"\n",
        "response = dispatcher(query, kural_data)\n",
        "print(response)\n",
        "\n",
        "query = \"KURAL 999\"\n",
        "response = dispatcher(query, kural_data)\n",
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Buw9TGWkpvrQ",
        "outputId": "27d689ae-d2b9-4b57-d271-88f577a99421"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kural 5: இருள்சேர் இருவினையும் சேரா இறைவன் பொருள்சேர் புகழ்புரிந்தார் மாட்டு.\n",
            "Meaning (English): The two-fold deeds that spring from darkness shall not adhere to those who delight in the true praise of God.\n",
            "An error occurred: You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9LXMCnGgeVBR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}